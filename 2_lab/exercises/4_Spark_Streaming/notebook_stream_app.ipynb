{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Spark Streaming Transform Data\nread data from Kafka topic, filter and reduce and write back to other Kafka Topic",
      "metadata": {},
      "id": "dbff7e9a"
    },
    {
      "cell_type": "code",
      "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nfrom pyspark.streaming import StreamingContext\nimport pyspark.sql.functions as f\n\n\nimport datetime\nfrom datetime import datetime\nimport json\n\n\n# use 95% of the screen for jupyter cell\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container {width:100% !important; }<style>\"))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ba0572c8"
    },
    {
      "cell_type": "code",
      "source": "appName=\"jupyter-stream\"\n\nconf = SparkConf()\n\n# CLUSTER MANAGER\n################################################################################\n# set Kubernetes Master as Cluster Manager(“k8s://https://” is NOT a typo, this is how Spark knows the “provider” type).\nconf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local:443\")\n\n# CONFIGURE KUBERNETES\n################################################################################\n# set the namespace that will be used for running the driver and executor pods.\nconf.set(\"spark.kubernetes.namespace\",\"frontend\")\n# set the docker image from which the Worker pods are created\nconf.set(\"spark.kubernetes.container.image\", \"thinkportgmbh/workshops:spark-3.3.1\")\nconf.set(\"spark.kubernetes.container.image.pullPolicy\", \"Always\")\n\n# set service account to be used\nconf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n# authentication for service account(required to create worker pods):\nconf.set(\"spark.kubernetes.authenticate.caCertFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\nconf.set(\"spark.kubernetes.authenticate.oauthTokenFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n\n\n# CONFIGURE SPARK\n################################################################################\nconf.set(\"spark.sql.adaptive.enabled\", \"False\")\n# set driver host. In this case the ingres service for the spark driver\n# find name of the driver service with 'kubectl get services' or in the helm chart configuration\nconf.set(\"spark.driver.host\", \"jupyter-spark-driver.frontend.svc.cluster.local\")\n# set the port, If this port is busy, spark-shell tries to bind to another port.\nconf.set(\"spark.driver.port\", \"29413\")\n# add the postgres driver jars into session\nconf.set(\"spark.jars\", \"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\nconf.set(\"spark.driver.extraClassPath\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\nconf.set(\"spark.executor.extraClassPath\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n#conf.set(\"spark.executor.extraLibrary\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar\")\n\n\n\n# CONFIGURE S3 CONNECTOR\nconf.set(\"spark.hadoop.fs.s3a.endpoint\", \"minio.minio.svc.cluster.local:9000\")\nconf.set(\"spark.hadoop.fs.s3a.access.key\", \"trainadm\")\nconf.set(\"spark.hadoop.fs.s3a.secret.key\", \"train@thinkport\")\nconf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\nconf.set(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\nconf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\nconf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n\n\n\n# conf.set(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\")\n\n# CONFIGURE WORKER (Customize based on workload)\n################################################################################\n# set number of worker pods\nconf.set(\"spark.executor.instances\", \"1\")\n# set memory of each worker pod\nconf.set(\"spark.executor.memory\", \"1G\")\n# set cpu of each worker pod\nconf.set(\"spark.executor.cores\", \"2\")\n\n# SPARK SESSION\n################################################################################\n# and last, create the spark session and pass it the config object\n\nspark = SparkSession\\\n    .builder\\\n    .config(conf=conf) \\\n    .config('spark.sql.session.timeZone', 'Europe/Berlin') \\\n    .appName(appName)\\\n    .getOrCreate()\n\n# also get the spark context\nsc=spark.sparkContext\nssc = StreamingContext(sc, 2)\n\n# change the log level to warning, to see less output\nsc.setLogLevel('WARN')\n\n# get the configuration object to check all the configurations the session was startet with\nfor entry in sc.getConf().getAll():\n        if entry[0] in [\"spark.app.name\",\"spark.kubernetes.namespace\",\"spark.executor.memory\",\"spark.executor.cores\",\"spark.driver.host\",\"spark.master\"]:\n            print(entry[0],\"=\",entry[1])\n            \n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c618dd27"
    },
    {
      "cell_type": "markdown",
      "source": "#### Read Stream from Kafka",
      "metadata": {},
      "id": "b436a47f"
    },
    {
      "cell_type": "code",
      "source": "# read stream from topic\ndf_step_1 = (spark\n      .readStream\n      .format(\"kafka\")\n      .option(\"kafka.bootstrap.servers\", \"kafka-cp-kafka.kafka.svc.cluster.local:9092\")\n      .option(\"subscribe\", \"twitter-table\")\n      .option(\"startingOffsets\", \"earliest\")\n      .load()\n     )\n\ndf_step_1.printSchema()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "31316ce9"
    },
    {
      "cell_type": "code",
      "source": "# schema des JSON Streams definieren\njsonSchema=StructType([\n    StructField('tweet_id', StringType(), False),\n    StructField('created_at', TimestampType(), False),\n    StructField('tweet_message', StringType(), True),\n    StructField('user_name', StringType(), True),\n    StructField('user_location', StringType(), True),\n    StructField('user_follower_count', IntegerType(), True),\n    StructField('user_friends_count', IntegerType(), True),\n    StructField('retweet_count', IntegerType(), True),\n    StructField('language', StringType(), True),\n    StructField('hashtags', ArrayType(StringType(), True), True)\n])\n\ndf_step_2= (df_step_1\n            # cast binary to string and string with json schema to json object\n            .select(f.from_json(f.col(\"value\").cast(\"string\"),jsonSchema).alias(\"t\"))\n            # un nest via\n            .select(\"t.*\")\n           )\n\ndf_step_2.printSchema()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b8dbff5a"
    },
    {
      "cell_type": "markdown",
      "source": "#### For Debugging: write stream to console",
      "metadata": {},
      "id": "c4c2e5fa"
    },
    {
      "cell_type": "code",
      "source": "stream_query_debug=(df_step_2\n                    .writeStream.format(\"console\")\n                    .option(\"truncate\", \"false\")\n                    .outputMode(\"append\")\n                    .start()\n                    .awaitTermination()\n                   )",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8c9ab96e"
    },
    {
      "cell_type": "code",
      "source": "s3_write_avro=(df_step_2\n          .writeStream\n          .format(\"avro\")\n          .outputMode(\"append\")\n          .option(\"path\", \"s3a://twitter/avro\")\n          .option(\"checkpointLocation\", \"/opt/spark/work-dir/\")\n          .trigger(processingTime='10 seconds')\n          .start()\n          .awaitTermination()\n         )",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "119c7409"
    },
    {
      "cell_type": "markdown",
      "source": "# BITTE Spark herunterfahren",
      "metadata": {},
      "id": "3916062d-5cde-4156-a712-ffd241dd2319"
    },
    {
      "cell_type": "code",
      "source": "# Terminate Spark Session\n# shut down executor pods\nspark.stop()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "76213f4b"
    }
  ]
}