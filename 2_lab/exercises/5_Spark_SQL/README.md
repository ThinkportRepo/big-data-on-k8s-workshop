# Spark SQL Aufgaben

Die Aufgaben mit Spark sind in verschiedenen Themen unterteilt. Die Aufgaben werden alle in Jupyter Notebooks ausgeführt in denen diese auch im Detail beschriebens sind.
Folge die Anleitung im Notebook.

### Big Data Dateiformate

Playground zum Kennenlernen und Verstehen der verschiedenen Datenformate wie Avro, Parquet, Delta, Iceberg
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_file_formats.ipynb`

### Spark ETL Pipeline

Einfache Datentransformations Pipeline. Das Ausführen dieser Pipeline ist wichtig, damit die Daten später mit Trino zur Verfügung stehen
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_etl.ipynb`

### Spark ad hoc Analysen

Verschiedene Datenanalysen unter Verwendung der Dataframe und SQL Abstraktion
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_analysis.ipynb`

Folgene Webseiten und Dokumentationen können dabei helfen.

- https://sparkbyexamples.com/pyspark-tutorial/
- https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html
