# Spark SQL Aufgaben

Die Aufgaben mit Spark sind in verschiedenen Themen unterteilt. Die Aufgaben werden alle in Jupyter Notebooks ausgeführt in denen diese auch im Detail beschriebens sind.
Folge die Anleitung im Notebook.

### Spark ETL Pipeline (Pflicht, damit die Folgeaufgaben funktionieren)

Einfache Datentransformations Pipeline
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_etl.ipynb`

### Spark ad hoc Analysen (Empfohlen)

Verschiedene Datenanalysen unter Verwendung der Dataframe und SQL Abstraktion
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_analysis.ipynb`

### Big Data Dateiformate (Optional)

Playground zum Kennenlernen und Verstehen der verschiedenen Datenformate wie Avro, Parquet, Delta, Iceberg, Hudi
`git/2_lab/exercises/5_Spark_SQL/notebook_spark_file_formats.ipynb`

Folgene Webseiten und Dokumentationen können dabei helfen.

- https://sparkbyexamples.com/pyspark-tutorial/
- https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html
