apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: stream-to-s3
  namespace: spark
  labels:
    app: spark-app
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: "thinkportgmbh/workshops:spark-3.3.1"
  imagePullPolicy: IfNotPresent # or Always
  # Python Script/Java Jar that should be submitted
  mainApplicationFile: s3a://scripts/spark_stream_to_s3.py
  sparkVersion: "3.3.1"
  # extra Spark configurations
  # https://dataflint.gitbook.io/dataflint-for-spark/getting-started/install-on-spark
  deps:
    packages:
      - io.dataflint:spark_2.12:0.1.2
  sparkConf:
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "file:/spark-logs"
    "spark.ui.prometheus.enabled": "true"
    "spark.executor.processTreeMetrics.enabled": "true"
    "spark.metrics.conf.*.sink.prometheusServlet.class": "org.apache.spark.metrics.sink.PrometheusServlet"
    "spark.metrics.conf.*.sink.prometheusServlet.path": "/metrics/prometheus"
    "spark.kubernetes.driver.annotation.prometheus.io/scrape": "true"
    "spark.kubernetes.driver.annotation.prometheus.io/path": "/metrics/executors/prometheus/"
    "spark.kubernetes.driver.annotation.prometheus.io/port": "4040"
    "spark.plugins": "io.dataflint.spark.SparkDataflintPlugin"
    "spark.driver.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp"
  # s3 connection configuration
  hadoopConf:
    "fs.s3a.endpoint": "minio.minio.svc.cluster.local:9000"
    "fs.s3a.access.key": "trainadm"
    "fs.s3a.secret.key": "train@thinkport"
    "fs.s3a.path.style.access": "true"
    "fs.s3.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
    "fs.s3a.connection.ssl.enabled": "false"
  ##############################################################
  # driver pod configuration
  ##############################################################
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.3.1
      app: spark-app-driver
    serviceAccount: spark
    env:
      - name: app_name
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: KAFKA_SERVER
        value: "kafka.kafka.svc.cluster.local:9092"
      - name: KAFKA_TOPIC
        value: "twitter-table"
    volumeMounts:
      - name: spark-history-server
        mountPath: /spark-logs
  ##############################################################
  # executor pod configuration
  ##############################################################
  executor:
    cores:
    instances: 1
    memory: "512m"
    labels:
      version: 3.3.1
      app: spark-app-executor
    volumeMounts:
      - name: spark-history-server
        mountPath: /spark-logs
  ##############################################################
  # volume definitions
  ##############################################################
  volumes:
    - name: spark-history-server
      persistentVolumeClaim:
        claimName: spark-history-server
