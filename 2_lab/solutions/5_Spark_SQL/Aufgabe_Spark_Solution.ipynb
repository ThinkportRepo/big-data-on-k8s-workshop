{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5765a06e",
   "metadata": {},
   "source": [
    "# Spark Aufgaben\n",
    "1. Importe laden\n",
    "2. Jupyter Spark starten und Twitter-Streams von Avro lesen\n",
    "3. Einlesen und Schreiben von Daten\n",
    "4. Analyse-Aufgaben erledigen \n",
    "5. Verlaufsanalyse durchführen\n",
    "6. **Ausschalten der Spark-App**\n",
    "\n",
    "## Wichtige Hinweise\n",
    "1. Führe alle Anweisungen in der vorgegebenen Reihenfolge aus. Die einzelnen Programmierzellen bauen aufeinander auf.\n",
    "2. **Beende unbedingt am Ende die Spark-Anwendung mit dem untersten Befehl \"spark.stop()\" , wenn du aufhörst an den Daten zu arbeiten.**\n",
    "3. Du kannst jederzeit das Notebook wieder hochfahren, wenn du Schritt 1 & 2 (Laden der Imports & Jupyter Spark und seine Konfigurationen hochfahren) ausführen.\n",
    "4. Mit **\"Strg\" + \"Enter\"** führst du einzelne Zellen direkt aus.\n",
    "5. In der oberen Leiste kannst du über **\"Insert\"** weitere Zellen hinzufügen, um weitere Test-Funktionen zu schreiben. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9d1f3",
   "metadata": {},
   "source": [
    "## 1. Laden der Imports\n",
    "Hier werden alle benötigten Libraries für dieses Lab heruntergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebe3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29706/1413759690.py:20: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import lower, col\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from delta import *\n",
    "\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "# use 95% of the screen for jupyter cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579b387",
   "metadata": {},
   "source": [
    "## 2. Jupyter Spark & Konfigurationen hochfahren\n",
    "Hier wird die App jupyter-spark konfiguriert und hochgefahren, welche unsere weiteren Schritte ausführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d15c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.kubernetes.namespace = frontend\n",
      "spark.master = k8s://https://kubernetes.default.svc.cluster.local:443\n",
      "spark.app.name = jupyter-spark\n",
      "spark.executor.memory = 1G\n",
      "spark.executor.cores = 2\n",
      "spark.driver.host = jupyter-spark-driver.frontend.svc.cluster.local\n"
     ]
    }
   ],
   "source": [
    "appName=\"jupyter-spark\"\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "# CLUSTER MANAGER\n",
    "################################################################################\n",
    "# set Kubernetes Master as Cluster Manager(“k8s://https://” is NOT a typo, this is how Spark knows the “provider” type).\n",
    "conf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local:443\")\n",
    "\n",
    "# CONFIGURE KUBERNETES\n",
    "################################################################################\n",
    "# set the namespace that will be used for running the driver and executor pods.\n",
    "conf.set(\"spark.kubernetes.namespace\",\"frontend\")\n",
    "# set the docker image from which the Worker pods are created\n",
    "conf.set(\"spark.kubernetes.container.image\", \"thinkportgmbh/workshops:spark-3.3.1\")\n",
    "conf.set(\"spark.kubernetes.container.image.pullPolicy\", \"Always\")\n",
    "\n",
    "# set service account to be used\n",
    "conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n",
    "# authentication for service account(required to create worker pods):\n",
    "conf.set(\"spark.kubernetes.authenticate.caCertFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\n",
    "conf.set(\"spark.kubernetes.authenticate.oauthTokenFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n",
    "\n",
    "\n",
    "# CONFIGURE SPARK\n",
    "################################################################################\n",
    "conf.set(\"spark.sql.session.timeZone\", \"Europe/Berlin\")\n",
    "# set driver host. In this case the ingres service for the spark driver\n",
    "# find name of the driver service with 'kubectl get services' or in the helm chart configuration\n",
    "conf.set(\"spark.driver.host\", \"jupyter-spark-driver.frontend.svc.cluster.local\")\n",
    "# set the port, If this port is busy, spark-shell tries to bind to another port.\n",
    "conf.set(\"spark.driver.port\", \"29413\")\n",
    "# add the postgres driver jars into session\n",
    "conf.set(\"spark.jars\", \"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "#conf.set(\"spark.driver.extraClassPath\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "conf.set(\"spark.executor.extraClassPath\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar, /opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "#conf.set(\"spark.executor.extraLibrary\",\"/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /opt/spark/jars/kafka-clients-3.3.1.jar\")\n",
    "\n",
    "# CONFIGURE S3 CONNECTOR\n",
    "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"minio.minio.svc.cluster.local:9000\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.access.key\", \"trainadm\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"train@thinkport\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "conf.set(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "\n",
    "# conf.set(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\")\n",
    "\n",
    "# CONFIGURE WORKER (Customize based on workload)\n",
    "################################################################################\n",
    "# set number of worker pods\n",
    "conf.set(\"spark.executor.instances\", \"1\")\n",
    "# set memory of each worker pod\n",
    "conf.set(\"spark.executor.memory\", \"1G\")\n",
    "# set cpu of each worker pod\n",
    "conf.set(\"spark.executor.cores\", \"2\")\n",
    "# Number of possible tasks = cores * executores\n",
    "\n",
    "# SPARK SESSION\n",
    "################################################################################\n",
    "# and last, create the spark session and pass it the config object\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(conf=conf) \\\n",
    "    .config('spark.sql.session.timeZone', 'Europe/Berlin') \\\n",
    "    .appName(appName)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# also get the spark context\n",
    "sc=spark.sparkContext\n",
    "# change the log level to warning, to see less output\n",
    "sc.setLogLevel('WARN')\n",
    "\n",
    "# get the configuration object to check all the configurations the session was startet with\n",
    "for entry in sc.getConf().getAll():\n",
    "        if entry[0] in [\"spark.app.name\",\"spark.kubernetes.namespace\",\"spark.executor.memory\",\"spark.executor.cores\",\"spark.driver.host\",\"spark.master\"]:\n",
    "            print(entry[0],\"=\",entry[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42ed16",
   "metadata": {},
   "source": [
    "## 3. Einlesen und Schreiben von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbac52",
   "metadata": {},
   "source": [
    "### 3.1 Einlesen der Daten aus unserem S3 Speicher-Bucket \n",
    "Laden der Daten aus unserem Bucket in \"s3a://twitter/avro\" in einen DataFrame, um auf den Daten zu arbeiten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b65543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 16:16:59 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df=(spark\n",
    "    .read.format(\"avro\")\n",
    "    .load(\"s3a://twitter/avro\")\n",
    "    .filter(f.array_contains(f.col(\"hashtags\"),\"BigData\")==True)\n",
    "    .repartition(20)\n",
    "   ).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31f3ee",
   "metadata": {},
   "source": [
    "Erste Ausgabe der Daten in Form eines DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dec3929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600615274516025345|2022-12-07 23:16:34|RT @Eli_Krumova: ...|      RpatoolsC|                null|                879|                31|            0|      en|[NeuralNetworks, ...|\n",
      "|1600501666285064192|2022-12-07 15:45:07|RT @Analytics_699...|  DasFintechBot|                null|                927|               322|            0|      en|[Analytics, BigDa...|\n",
      "|1600476000349204481|2022-12-07 14:03:08|Tecnologías como ...|  Blockmedia_es|   Barcelona, España|                496|               139|            0|      es|[BigData, Blockch...|\n",
      "|1600538150144966657|2022-12-07 18:10:06|Buy #Facebook Rev...|   some73552272|           new york |                773|              1102|            0|      en|[Facebook, Machin...|\n",
      "|1600503765521629188|2022-12-07 15:53:28|Artificial Intell...|    IainLJBrown|              Marlow|             113804|             96748|            0|      en|[ArtificialIntell...|\n",
      "|1600489447317028868|2022-12-07 14:56:34|For quality assig...|  ResearchGuru6|       New York, USA|               1443|              1534|            0|      en|[Essays, Research...|\n",
      "|1600524928792551425|2022-12-07 17:17:33|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              43643|              2260|            0|      en|[DataManagement, ...|\n",
      "|1600823008414773248|2022-12-08 13:02:01|RT @botdmtktwo: J...|  Long_Shot_Ads|        Dearborn, MI|                602|              2173|            0|      en|[BigData, Analyti...|\n",
      "|1600567264494768128|2022-12-07 20:05:47|Build an #IoT App...|     KirkDBorne|       Maryland, USA|             371860|              8227|            0|      en|[IoT, TimeSeries,...|\n",
      "|1600542707214012416|2022-12-07 18:28:12|Buy #Android App ...|   each28517571|                null|                427|               537|            0|      en|[Android, Machine...|\n",
      "|1600503908169879554|2022-12-07 15:54:02|RT @Analytics_699...|  flutterbyamey|        Flutterverse|                855|                22|            0|      fr|[Analytics, Machi...|\n",
      "|1600503878880993284|2022-12-07 15:53:55|RT @WorldTrendsIn...|     ArceoChoya|  West Hollywood, CA|               1782|              1231|            0|      en|[DeepLearning, Io...|\n",
      "|1600489192483586050|2022-12-07 14:55:33|For quality assig...|  ResearchGuru6|       New York, USA|               1443|              1534|            0|      en|[Essays, Research...|\n",
      "|1600817661742665731|2022-12-08 12:40:46|RT @gp_pulipaka: ...|_serverlessbot_|                null|               1135|              5008|            0|      en|[BigData, Analyti...|\n",
      "|1600834122028810241|2022-12-08 13:46:11|Free Udemy Certif...|    LexiBiancia|                null|                  5|                 0|            0|      en|[Developers, DEVC...|\n",
      "|1600548429566033931|2022-12-07 18:50:57|RT @gp_pulipaka: ...|   sonurawal931|    Rajasthan, India|                147|                32|            0|      en|[BigData, Analyti...|\n",
      "|1600629826813042692|2022-12-08 00:14:23|Hmu for Excel ass...|   elitepwriter|     New Orleans, LA|                281|               771|            0|      en|[ArtificialIntell...|\n",
      "|1600524057350242305|2022-12-07 17:14:06|Buy #Verified Fac...|   some73552272|           new york |                773|              1100|            0|      en|[Verified, Machin...|\n",
      "|1600529560554344449|2022-12-07 17:35:58|RT @digitaledwinc...|   chidambara09|Mysore & 𝗕𝗘𝗥𝗟...|              11093|                13|            0|      en|[DataManagement, ...|\n",
      "|1600505419234942980|2022-12-07 16:00:02|RT @Analytics_699...|  RobotConsumer|                null|               4018|                36|            0|      en|[Analytics, BigDa...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da71da4",
   "metadata": {},
   "source": [
    "### 3.2 Schreiben der Daten ins Delta-Format\n",
    "Hier werden die Daten direkt im Delta-Format umgewandelt und in den S3-Bucket \"s3a://twitter/delta\" geschrieben. Dieser Schritt ist wichtig, um die Daten passend für Trino zu abzulegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6249e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "writer_delta=(df\n",
    "                #.where(f.col(\"tweet_language\").isin(\"en\",\"de\"))\n",
    "                .write.partitionBy(\"language\")\n",
    "                .mode(\"overwrite\")\n",
    "                .format(\"delta\")\n",
    "                .option(\"overwriteSchema\", \"true\")\n",
    "                .option(\"userMetadata\", \"Initial Ladung\")\n",
    "                .save(\"s3a://twitter/delta\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518be64b",
   "metadata": {},
   "source": [
    "## 4. Analyse-Aufgaben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b79d70",
   "metadata": {},
   "source": [
    "### 4.1 Tweets anschauen und den Aufbau des Dataframes\n",
    "Schau dir den Datensatz einmal genau an. Welche Spalten gibt es? Welche Datentypen sind vorhanden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406525a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600615274516025345|2022-12-07 23:16:34|RT @Eli_Krumova: ...|      RpatoolsC|                null|                879|                31|            0|      en|[NeuralNetworks, ...|\n",
      "|1600501666285064192|2022-12-07 15:45:07|RT @Analytics_699...|  DasFintechBot|                null|                927|               322|            0|      en|[Analytics, BigDa...|\n",
      "|1600476000349204481|2022-12-07 14:03:08|Tecnologías como ...|  Blockmedia_es|   Barcelona, España|                496|               139|            0|      es|[BigData, Blockch...|\n",
      "|1600538150144966657|2022-12-07 18:10:06|Buy #Facebook Rev...|   some73552272|           new york |                773|              1102|            0|      en|[Facebook, Machin...|\n",
      "|1600503765521629188|2022-12-07 15:53:28|Artificial Intell...|    IainLJBrown|              Marlow|             113804|             96748|            0|      en|[ArtificialIntell...|\n",
      "|1600489447317028868|2022-12-07 14:56:34|For quality assig...|  ResearchGuru6|       New York, USA|               1443|              1534|            0|      en|[Essays, Research...|\n",
      "|1600524928792551425|2022-12-07 17:17:33|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              43643|              2260|            0|      en|[DataManagement, ...|\n",
      "|1600823008414773248|2022-12-08 13:02:01|RT @botdmtktwo: J...|  Long_Shot_Ads|        Dearborn, MI|                602|              2173|            0|      en|[BigData, Analyti...|\n",
      "|1600567264494768128|2022-12-07 20:05:47|Build an #IoT App...|     KirkDBorne|       Maryland, USA|             371860|              8227|            0|      en|[IoT, TimeSeries,...|\n",
      "|1600542707214012416|2022-12-07 18:28:12|Buy #Android App ...|   each28517571|                null|                427|               537|            0|      en|[Android, Machine...|\n",
      "|1600503908169879554|2022-12-07 15:54:02|RT @Analytics_699...|  flutterbyamey|        Flutterverse|                855|                22|            0|      fr|[Analytics, Machi...|\n",
      "|1600503878880993284|2022-12-07 15:53:55|RT @WorldTrendsIn...|     ArceoChoya|  West Hollywood, CA|               1782|              1231|            0|      en|[DeepLearning, Io...|\n",
      "|1600489192483586050|2022-12-07 14:55:33|For quality assig...|  ResearchGuru6|       New York, USA|               1443|              1534|            0|      en|[Essays, Research...|\n",
      "|1600817661742665731|2022-12-08 12:40:46|RT @gp_pulipaka: ...|_serverlessbot_|                null|               1135|              5008|            0|      en|[BigData, Analyti...|\n",
      "|1600834122028810241|2022-12-08 13:46:11|Free Udemy Certif...|    LexiBiancia|                null|                  5|                 0|            0|      en|[Developers, DEVC...|\n",
      "|1600548429566033931|2022-12-07 18:50:57|RT @gp_pulipaka: ...|   sonurawal931|    Rajasthan, India|                147|                32|            0|      en|[BigData, Analyti...|\n",
      "|1600629826813042692|2022-12-08 00:14:23|Hmu for Excel ass...|   elitepwriter|     New Orleans, LA|                281|               771|            0|      en|[ArtificialIntell...|\n",
      "|1600524057350242305|2022-12-07 17:14:06|Buy #Verified Fac...|   some73552272|           new york |                773|              1100|            0|      en|[Verified, Machin...|\n",
      "|1600529560554344449|2022-12-07 17:35:58|RT @digitaledwinc...|   chidambara09|Mysore & 𝗕𝗘𝗥𝗟...|              11093|                13|            0|      en|[DataManagement, ...|\n",
      "|1600505419234942980|2022-12-07 16:00:02|RT @Analytics_699...|  RobotConsumer|                null|               4018|                36|            0|      en|[Analytics, BigDa...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4223d1",
   "metadata": {},
   "source": [
    "### 4.2  Das Schema des Datensatzes anzeigen \n",
    "<br>\n",
    "<code> df.printSchema()</code> gibt das Schema des Datensatzes aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196c1696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- tweet_message: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- user_follower_count: integer (nullable = true)\n",
      " |-- user_friends_count: integer (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc238b9",
   "metadata": {},
   "source": [
    "### 4.3 Zählen der Tweets pro Stunde\n",
    "Schreibe eine Abfrage, die **die Anzahl an Tweets pro Stunde** zählt.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_hourly=(df\n",
    "            .withColumn(\"hour\", f.hour(f.col(\"created_at\")))\n",
    "            .groupBy(\"hour\")\n",
    "            .count()\n",
    "            .withColumnRenamed(\"count\",\"total\")\n",
    "            .sort(\"hour\")\n",
    "          )\n",
    "df_hourly.show(20)</code>\n",
    "</details>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1185327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:==================================================>     (18 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|hour|total|\n",
      "+----+-----+\n",
      "|   0|  121|\n",
      "|   1|   79|\n",
      "|   2|   62|\n",
      "|   3|  105|\n",
      "|   4|   94|\n",
      "|   5|  115|\n",
      "|   6|  151|\n",
      "|   7|  203|\n",
      "|   8|  182|\n",
      "|   9|  128|\n",
      "|  10|  144|\n",
      "|  11|  140|\n",
      "|  12|  130|\n",
      "|  13|  193|\n",
      "|  14|  197|\n",
      "|  15|  174|\n",
      "|  16|  156|\n",
      "|  17|  324|\n",
      "|  18|  282|\n",
      "|  19|  143|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_hourly=(df  \n",
    "            .withColumn(\"hour\", f.hour(f.col(\"created_at\")))\n",
    "            .groupBy(\"hour\")\n",
    "            .count()\n",
    "            .withColumnRenamed(\"count\",\"total\")\n",
    "            .sort(\"hour\")\n",
    "          )\n",
    "\n",
    "df_hourly.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d5a8f",
   "metadata": {},
   "source": [
    "### 4.4 Top 10 User nach Tweet-Anzahl\n",
    "Schreibe eine Abfrage, die die **Top User** nach ihrer **Anzahl an Tweets** ausgibt. Bedenke dabei, deine Ausgabe auf **10** Einträge zu limitieren.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_top_user=(df\n",
    "                .groupBy(\"user_name\")\n",
    "                .agg(\n",
    "                    f.count(\"user_name\").alias(\"numberOfTweets\")\n",
    "                    )\n",
    "                .orderBy(f.col(\"numberOfTweets\").desc())\n",
    "                .limit(10)\n",
    "                .withColumnRenamed(\"user_name\",\"user\")\n",
    "                )\n",
    "df_top_user.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a6ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:============================================>           (16 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|           user|numberOfTweets|\n",
      "+---------------+--------------+\n",
      "|    Eli_Krumova|           157|\n",
      "| Khulood_Almani|           107|\n",
      "|        sdogdev|            95|\n",
      "|    LexiBiancia|            55|\n",
      "|      BigDataF1|            54|\n",
      "|    uCloudifyAI|            53|\n",
      "|SAMUELS02077409|            45|\n",
      "|       sectest9|            42|\n",
      "|     BoredomBot|            41|\n",
      "|programminbuddy|            40|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_top_user=(df\n",
    "                .groupBy(\"user_name\")\n",
    "                .agg(\n",
    "                    f.count(\"user_name\").alias(\"numberOfTweets\")\n",
    "                    )\n",
    "                .orderBy(f.col(\"numberOfTweets\").desc())\n",
    "                .limit(10)\n",
    "                .withColumnRenamed(\"user_name\",\"user\")\n",
    "                )\n",
    "df_top_user.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75828392",
   "metadata": {},
   "source": [
    "### 4.5 Umgang mit Trino Arrays\n",
    "Für die folgenden Aufgabe wird die <code>explode</code>-Funktion benötigt. Schreibe eine Abfrage die das Hashtag-array mit <code>explode</code> teilt. Gebe dabei die Spalten \"user_name\", \"tweet_id\"und die explodierte\"hashtags\"- Spalte mit einem Limit von 20 Zeilen aus. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_hash=(df\n",
    "         .withColumn(\"hashtags\",explode(\"hashtags\"))\n",
    "        .limit(20)\n",
    "        .select(\"user_name\", \"tweet_id\", \"hashtags\")\n",
    "        )\n",
    "df_hash.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd44fd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------+\n",
      "|    user_name|           tweet_id|       hashtags|\n",
      "+-------------+-------------------+---------------+\n",
      "|    RpatoolsC|1600615274516025345| NeuralNetworks|\n",
      "|    RpatoolsC|1600615274516025345| DataScientists|\n",
      "|    RpatoolsC|1600615274516025345|    DataScience|\n",
      "|    RpatoolsC|1600615274516025345|MachineLearning|\n",
      "|    RpatoolsC|1600615274516025345|      Analytics|\n",
      "|    RpatoolsC|1600615274516025345|             AI|\n",
      "|    RpatoolsC|1600615274516025345|             ML|\n",
      "|    RpatoolsC|1600615274516025345|        BigData|\n",
      "|    RpatoolsC|1600615274516025345|   DeepLearning|\n",
      "|DasFintechBot|1600501666285064192|      Analytics|\n",
      "|DasFintechBot|1600501666285064192|        BigData|\n",
      "|DasFintechBot|1600501666285064192|             AI|\n",
      "|DasFintechBot|1600501666285064192|         Python|\n",
      "|DasFintechBot|1600501666285064192|MachineLearning|\n",
      "|Blockmedia_es|1600476000349204481|        BigData|\n",
      "|Blockmedia_es|1600476000349204481|     Blockchain|\n",
      "| some73552272|1600538150144966657|       Facebook|\n",
      "| some73552272|1600538150144966657|MachineLearning|\n",
      "| some73552272|1600538150144966657|    DataScience|\n",
      "| some73552272|1600538150144966657|             5G|\n",
      "+-------------+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hash=(df\n",
    "         .withColumn(\"hashtags\",explode(\"hashtags\"))\n",
    "         .limit(20)\n",
    "         .select(\"user_name\", \"tweet_id\", \"hashtags\")\n",
    "        )\n",
    "df_hash.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58765db1",
   "metadata": {},
   "source": [
    "### 4.6 Top 5 Hashtags der Top 10 User\n",
    "Schreibe eine Abfrage, die die **Top 5 der Hashtags** der **10 User** mit den **meisten Tweets** ausgibt.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_top5_per_user=(df_top_user\n",
    "            # filter via join\n",
    "            .join(df,[df_top_user.user==df.user_name],how=\"left\")\n",
    "            # hashtags array in Zeilen Einträge exploden\n",
    "            .withColumn(\"hashtags\",explode(\"hashtags\"))\n",
    "            # hashtags lowercase schreiben um Doppelungen zu entfernen\n",
    "            .withColumn(\"hashtags\", lower(col('hashtags')))\n",
    "            # groupieren und counten by hashtag\n",
    "            .groupBy(\"hashtags\").agg(f.count(\"hashtags\"))\n",
    "            # rückwärts sortieren\n",
    "            .sort(f.col(\"count(hashtags)\").desc())\n",
    "            # top 5 selectieren\n",
    "            .limit(5) \n",
    "                 )\n",
    "df_top5_per_user.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0bd4d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:===============================================>        (17 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|   hashtags|count(hashtags)|\n",
      "+-----------+---------------+\n",
      "|    bigdata|            689|\n",
      "|datascience|            413|\n",
      "|         ai|            353|\n",
      "|  analytics|            353|\n",
      "|        iot|            323|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top5_per_user=(df_top_user\n",
    "            # filter via join\n",
    "            .join(df,[df_top_user.user==df.user_name],how=\"left\")\n",
    "            # hashtags array in Zeilen Einträge exploden\n",
    "            .withColumn(\"hashtags\",explode(\"hashtags\"))\n",
    "            # hashtags lowercase schreiben um Doppelungen zu entfernen\n",
    "            .withColumn(\"hashtags\", lower(col('hashtags')))\n",
    "            # groupieren und counten by hashtag\n",
    "            .groupBy(\"hashtags\").agg(f.count(\"hashtags\"))      \n",
    "            # rückwärts sortieren\n",
    "            .sort(f.col(\"count(hashtags)\").desc())\n",
    "            # top 5 selectieren\n",
    "            .limit(5)\n",
    "                 )\n",
    "df_top5_per_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb68e6c",
   "metadata": {},
   "source": [
    " ### 4.7 Top 10 Influencer (User mit #BigData-tweets mit den meisten Followern) \n",
    " Schreibe eine Abfrage, die die **Top 10 Influencer** mit den **meisten Follower** zählt und sortiert anzeigt.\n",
    " <br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_top_influencer=(df\n",
    "                .groupBy(\"user_name\")\n",
    "                .agg(\n",
    "                    f.max(\"user_follower_count\").alias(\"follower\")\n",
    "                    )\n",
    "                .orderBy(f.col(\"follower\").desc())\n",
    "                )\n",
    "df_top_influencer.show(10)</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79b5113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:============================================>           (16 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|      user_name|follower|\n",
      "+---------------+--------+\n",
      "|     KirkDBorne|  372126|\n",
      "| Ronald_vanLoon|  294843|\n",
      "|    EU_Eurostat|  202308|\n",
      "|     Jilliemary|  177110|\n",
      "|StartGrowthHack|  176425|\n",
      "|         rwang0|  140016|\n",
      "|    gp_pulipaka|  133078|\n",
      "|    ipfconline1|  128763|\n",
      "|     CyrilCoste|  121560|\n",
      "|DataScienceDojo|  116256|\n",
      "+---------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_top_influencer=(df\n",
    "                .groupBy(\"user_name\")\n",
    "                .agg(\n",
    "                    f.max(\"user_follower_count\").alias(\"follower\")\n",
    "                    )\n",
    "                .orderBy(f.col(\"follower\").desc())\n",
    "                   \n",
    "                )\n",
    "df_top_influencer.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e6148",
   "metadata": {},
   "source": [
    "### 4.8 Top 10 Influencer und ihre Anzahl an tweets\n",
    "Schreibe eine Abfrage, die die **Top 10 Influencer**, ihre Follower und die **Anzahl ihrer Tweets** ausgibt. außeredem soll es sortiert nach den Anzahl ihrer Follower sein. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_withRetweets=(df_top_user\n",
    "            # filter via join auf die Top 10 Influencer\n",
    "            .join(df_top_influencer, [df_top_influencer.user_name==df_top_user.user],how=\"left\")\n",
    "            .orderBy(f.col(\"follower\").desc())\n",
    "            .limit(10)\n",
    "            .drop(\"user_name\")\n",
    "            .select(\"user\",\"follower\",\"numberOfTweets\")\n",
    "    )\n",
    "df_withRetweets.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e47a7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+--------------+\n",
      "|           user|follower|numberOfTweets|\n",
      "+---------------+--------+--------------+\n",
      "| Khulood_Almani|   44910|           107|\n",
      "|       sectest9|   43772|            42|\n",
      "|    Eli_Krumova|   31375|           157|\n",
      "|programminbuddy|    1261|            40|\n",
      "|    uCloudifyAI|    1111|            53|\n",
      "|     BoredomBot|     242|            41|\n",
      "|      BigDataF1|     200|            54|\n",
      "|        sdogdev|      60|            95|\n",
      "|    LexiBiancia|       6|            55|\n",
      "|SAMUELS02077409|       1|            45|\n",
      "+---------------+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_withRetweets=(df_top_user\n",
    "            # filter via join auf die Top 10 Influencer\n",
    "            .join(df_top_influencer, [df_top_influencer.user_name==df_top_user.user],how=\"left\") \n",
    "            .orderBy(f.col(\"follower\").desc())\n",
    "            .limit(10)\n",
    "            .drop(\"user_name\")   \n",
    "            .select(\"user\",\"follower\",\"numberOfTweets\")\n",
    "            \n",
    "    )\n",
    "\n",
    "df_withRetweets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13676250",
   "metadata": {},
   "source": [
    "### Bonusaufgabe: Filter nach den Top 10 Locations und ihrem Top Hashtag\n",
    "Schreibe eine Abfrage, die die **Top 10 häufigsten Locations** ausgibt und das am **zweitmeisten verwendete Hashtag** dort. Da alle unsere Daten das Hashtag #BigData beinhalten. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df3=(df\n",
    "    .select(\"user_location\")\n",
    "    .where(~f.col(\"user_location\").isin(\"\",\"null\",\"REMOTE\",\"Earth\"))\n",
    "    .groupBy(\"user_location\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\",\"location_total\")\n",
    "    .orderBy(f.col(\"location_total\").desc())\n",
    "    .limit(10)\n",
    "    )</code>\n",
    "    \n",
    "<code>df4=(df\n",
    "    .select(\"user_location\",\"hashtags\")\n",
    "    .withColumn(\"singletag\",f.explode(f.col(\"hashtags\")))\n",
    "    .groupBy(\"user_location\",\"singletag\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\",\"tags_total\")\n",
    "        )</code>\n",
    "    \n",
    "<code>df5=(df3.alias(\"a\")\n",
    "    .join(f.broadcast(df4.alias(\"b\")),[df3.user_location==df4.user_location],how=\"left\")\n",
    "    .select(\"a.user_location\",\"a.location_total\",\"b.singletag\",\"b.tags_total\")      \n",
    "    .withColumn(\"rank\",f.row_number().over(Window.partitionBy(\"a.user_location\")\n",
    "    .orderBy(f.col(\"b.tags_total\").desc())))\n",
    "    .filter(f.col(\"rank\")==1)\n",
    "    .sort(f.col(\"location_total\").desc())\n",
    "    .limit(10)\n",
    "    )\n",
    "df5.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f14e0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:==========================================>             (15 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|       user_location|location_total|\n",
      "+--------------------+--------------+\n",
      "|                  UK|           158|\n",
      "|Kingdom of Saudi ...|           111|\n",
      "|       United States|            76|\n",
      "|            new york|            72|\n",
      "|    Hyderabad, India|            61|\n",
      "|Rotterdam, The Ne...|            55|\n",
      "|       Mumbai, India|            45|\n",
      "|       New York, USA|            40|\n",
      "|                 UK |            38|\n",
      "|               India|            37|\n",
      "+--------------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df3=(df\n",
    "    .select(\"user_location\")\n",
    "    .where(~f.col(\"user_location\").isin(\"\",\"null\",\"REMOTE\",\"Earth\"))\n",
    "    .groupBy(\"user_location\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\",\"location_total\")\n",
    "    .orderBy(f.col(\"location_total\").desc())\n",
    "    .limit(10)\n",
    "    )\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb05cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:==================================================>     (18 + 2) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|       user_location|           singletag|tags_total|\n",
      "+--------------------+--------------------+----------+\n",
      "|   Orange County, CA|                IIoT|         3|\n",
      "|              España|           Analytics|         6|\n",
      "|                null|              travel|         2|\n",
      "|                null|          creativity|        11|\n",
      "|       New York, USA|            Research|         2|\n",
      "|Kingdom of Saudi ...|             digital|        32|\n",
      "|   Orange County, CA|       Cybersecurity|         3|\n",
      "|            Pakistan|              Misery|         2|\n",
      "|         Detroit, MI|      trendingkiiara|         7|\n",
      "|     Los Angeles, CA|              Python|        17|\n",
      "|                  UK|     DataEngineering|         1|\n",
      "|       Maryland, USA|        IoTCommunity|         4|\n",
      "|       Benito Juárez|                 IoT|        15|\n",
      "|Havre de Grace, M...|             BigData|        12|\n",
      "|               Egypt|                IIoT|         2|\n",
      "|                null|        devcommunity|         1|\n",
      "|       Maryland, USA|DigitalTransforma...|         3|\n",
      "|       Kentucky, USA|                  AI|        11|\n",
      "|       Paris, France|                Data|         3|\n",
      "|                 UK |                Meta|        36|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df4=(df\n",
    "    .select(\"user_location\",\"hashtags\")\n",
    "    .withColumn(\"singletag\",f.explode(f.col(\"hashtags\")))\n",
    "    .groupBy(\"user_location\",\"singletag\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\",\"tags_total\")\n",
    "    )\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "132149f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----------+----------+----+\n",
      "|       user_location|location_total|  singletag|tags_total|rank|\n",
      "+--------------------+--------------+-----------+----------+----+\n",
      "|                  UK|           158|DataScience|       135|   2|\n",
      "|Kingdom of Saudi ...|           111|         AI|        96|   2|\n",
      "|       United States|            76|     Python|        64|   2|\n",
      "|            new york|            72|        NLP|        72|   2|\n",
      "|    Hyderabad, India|            61|DataScience|        40|   2|\n",
      "|Rotterdam, The Ne...|            55|      DDW16|         6|   2|\n",
      "|       Mumbai, India|            45|  Analytics|        40|   2|\n",
      "|       New York, USA|            40|         AI|        32|   2|\n",
      "|                 UK |            38|DataScience|        38|   2|\n",
      "|               India|            37|         AI|        24|   2|\n",
      "+--------------------+--------------+-----------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5=(df3.alias(\"a\")\n",
    "    .join(f.broadcast(df4.alias(\"b\")),[df3.user_location==df4.user_location],how=\"left\")\n",
    "    .select(\"a.user_location\",\"a.location_total\",\"b.singletag\",\"b.tags_total\")\n",
    "    .withColumn(\"rank\",f.row_number().over(Window.partitionBy(\"a.user_location\").orderBy(f.col(\"b.tags_total\").desc())))\n",
    "    .filter(f.col(\"rank\")==2)\n",
    "    .sort(f.col(\"location_total\").desc())\n",
    "    .limit(10)\n",
    "    )\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081f82e",
   "metadata": {},
   "source": [
    "## 5. Delta History and Time Travel\n",
    "Führe den folgenden Code aus um die aktuelle Delta-Daten-Version upzudaten. Wenn du mehrere Versionen sehen willst schreibe öfter raus mit <code>writer_delta()</code> mit einigen Minuten Abstand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "287ada1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "writer_delta=(df\n",
    "                .write.partitionBy(\"language\")\n",
    "                .mode(\"overwrite\")\n",
    "                .format(\"delta\")\n",
    "                .option(\"overwriteSchema\", \"true\")\n",
    "                .option(\"userMetadata\", \"Update Ladung\")\n",
    "                .save(\"s3a://twitter/delta\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d10e78",
   "metadata": {},
   "source": [
    "### 5.1 Delta Tabelle ausgeben\n",
    "Lade die Delta-Tabelle und lasse dir die ersten 2 Einträge ausgeben.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code># Load Delta file in s3 into Delta Table Object\n",
    "dt = DeltaTable.forPath(spark, \"s3a://twitter/delta\")\n",
    "dt.toDF().show(2)</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f34013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+--------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|     user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+--------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600589057381306401|2022-12-07 21:32:23|@EstelaMandela @b...|Khulood_Almani|Kingdom of Saudi ...|              43586|              2261|            0|      en|[AI, Python, Data...|\n",
      "|1600525331085295616|2022-12-07 17:19:09|Free Udemy Certif...|      mikejo_m|                null|                 12|                 4|            0|      en|[Developers, DEVC...|\n",
      "+-------------------+-------------------+--------------------+--------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Delta file in s3 into Delta Table Object\n",
    "dt = DeltaTable.forPath(spark, \"s3a://twitter/delta\")\n",
    "dt.toDF().show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862d91",
   "metadata": {},
   "source": [
    "### 5.2  Erzeugen einer Historie\n",
    "1. Führe mehrmals Write to Delta aus und prüfe, wie die Historie neue Einträge hinzufügt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5127f540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+\n",
      "|version|readVersion|          timestamp|userId|operation| operationParameters|    operationMetrics|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+\n",
      "|     16|         15|2022-12-08 17:30:26|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|     15|         14|2022-12-08 17:27:47|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|     14|         13|2022-12-08 17:27:27|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|     13|         12|2022-12-08 17:27:05|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|     12|         11|2022-12-08 17:21:54|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|     11|         10|2022-12-08 16:55:59|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 54, ...|\n",
      "|     10|          9|2022-12-08 16:51:53|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 54, ...|\n",
      "|      9|          8|2022-12-08 16:41:54|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 54, ...|\n",
      "|      8|          7|2022-12-08 16:40:48|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 54, ...|\n",
      "|      7|          6|2022-12-08 16:38:54|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|      6|          5|2022-12-08 16:31:50|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|      5|          4|2022-12-08 16:29:03|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 198,...|\n",
      "|      4|          3|2022-12-08 12:26:50|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 54, ...|\n",
      "|      3|          2|2022-12-08 12:23:05|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 188,...|\n",
      "|      2|          1|2022-12-08 12:10:25|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 422,...|\n",
      "|      1|          0|2022-12-07 19:28:38| trino| OPTIMIZE|{queryId -> 20221...|                null|\n",
      "|      0|       null|2022-12-07 18:20:16|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 176,...|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the metadata for the full history of the table\n",
    "fullHistoryDF = dt.history()    \n",
    "\n",
    "# get the metadata for the last operation\n",
    "lastOperationDF = dt.history(1) \n",
    "\n",
    "fullHistoryDF.select(\"version\",\"readVersion\",\"timestamp\",\"userId\",\"operation\",\"operationParameters\",\"operationMetrics\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0a855",
   "metadata": {},
   "source": [
    "### 5.3 Laden einer  Versionen \n",
    "Lade eine der Versionen und lasse dir alle `languages` anzeigen (via distinct().show())\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df = spark.read.format(\"delta\").load(\"s3a://solution/twitter_delta\")\n",
    "df.select(\"language\").distinct().show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92161ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|      en|\n",
      "|     und|\n",
      "|     qht|\n",
      "|      es|\n",
      "|      it|\n",
      "|      ar|\n",
      "|      sv|\n",
      "|     qme|\n",
      "|      fr|\n",
      "|      pl|\n",
      "|      pt|\n",
      "|      in|\n",
      "|      tr|\n",
      "|      de|\n",
      "|      no|\n",
      "|      ro|\n",
      "|      tl|\n",
      "|      hu|\n",
      "|      ca|\n",
      "|      ht|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600475534689026049|2022-12-07 14:01:17|AIM spoke to @Ree...|Analyticsindiam|    Bengaluru, India|              15350|               483|            0|      en|[quantumcomputing...|\n",
      "|1600475603202981889|2022-12-07 14:01:33|Micro Focus and J...|     jenna_loup|         Houston, TX|                 97|               102|            0|      en|[sustainability, ...|\n",
      "|1600475677743980544|2022-12-07 14:01:51|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataScientist, J...|\n",
      "|1600475711029989376|2022-12-07 14:01:59|RT @ghostx1010: E...|   falconX_1010|                null|                  3|               203|            0|      en|[MachineLearning,...|\n",
      "|1600475715505373184|2022-12-07 14:02:00|How to Transform ...|   DivergentCIO|         Kansas City|              29734|             28024|            0|      en|[EmergingTech, AI...|\n",
      "|1600475778503696384|2022-12-07 14:02:15|RT @Khulood_Alman...|   HAMDANLAVI89| Hafr Al Batin, KSA.|                225|               458|            0|      en|[Data, AI, Python...|\n",
      "|1600475800909717505|2022-12-07 14:02:20|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataAnalytics, S...|\n",
      "|1600475803912994816|2022-12-07 14:02:21|RT @Khulood_Alman...|  flutterbyamey|        Flutterverse|                855|                22|            0|      en|[Data, AI, Python...|\n",
      "|1600475805641064448|2022-12-07 14:02:22|Six Ways Artifici...|  terence_mills|New York | London...|              16043|              8615|            0|      en|[AI, AIio, BigDat...|\n",
      "|1600476059228524544|2022-12-07 14:03:22|RT @HaroldSinnott...|     Untukmassa|Yogyakarta, Indon...|                100|              1481|            0|      en|[SQL, MachineLear...|\n",
      "|1600475661529133057|2022-12-07 14:01:47|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              43619|              2259|            0|      en|[Data, AI, Python...|\n",
      "|1600476054220857344|2022-12-07 14:03:21|A China-linked na...| HexBuddy127001|                null|                 17|               106|            0|      en|[MachineLearning,...|\n",
      "|1600501676586270721|2022-12-07 15:45:10|Why We Migrated F...|   dataclaudius|           Zürich CH|               3215|              2839|            0|      en|[BigData, Analyti...|\n",
      "|1600501681703342080|2022-12-07 15:45:11|Federated Machine...|          goq7v|                null|               1201|              1200|            0|      en|[BigData, learnin...|\n",
      "|1600540645235605506|2022-12-07 18:20:01|Applications of s...|     ingliguori|         Italia 🇮🇹|              48693|              9137|            0|      en|[DigitalTransform...|\n",
      "|1600524775952379904|2022-12-07 17:16:57|RT @Sheraj99: #Li...|  gavaskart1996|        புதுக்கோட்டை|                354|               301|            0|      en|[Linux, MachineLe...|\n",
      "|1600524782201556997|2022-12-07 17:16:59|The first one, yo...|JoannBr21047226|              Canada|                588|              1864|            0|      en|[FraudDetection, ...|\n",
      "|1600615238977601536|2022-12-07 23:16:25|RT @Eli_Krumova: ...|    Eli_Krumova|                  UK|              31372|             23507|            0|      en|[Python, CheatShe...|\n",
      "|1600615259613851648|2022-12-07 23:16:30|RT @m2mtechconnec...|abhinav_singwal|                null|                206|               898|            0|      en|[VR, AR, Cloud, B...|\n",
      "|1600615273144393746|2022-12-07 23:16:33|RT @Eli_Krumova: ...|      RpatoolsC|                null|                879|                31|            0|      en|[DataScientist, D...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load latest delta version\n",
    "df = spark.read.format(\"delta\").load(\"s3a://solution/twitter_delta\")\n",
    "df.select(\"language\").distinct().show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cee9d7",
   "metadata": {},
   "source": [
    "### 5.4. Laden einer ältere Versionen \n",
    "Lade eine ältere Version und bestätige, dass noch alle Daten vorhanden sind.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_timetravel_old = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(\"s3a://twitter/delta\")\n",
    "df_timetravel_old.select(\"language\").distinct().show()\n",
    "df_timetravel_old.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85e31aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|      en|\n",
      "|     und|\n",
      "|     qht|\n",
      "|      es|\n",
      "|      it|\n",
      "|      ar|\n",
      "|      sv|\n",
      "|     qme|\n",
      "|      fr|\n",
      "|      pl|\n",
      "|      pt|\n",
      "|      in|\n",
      "|      tr|\n",
      "|      de|\n",
      "|      no|\n",
      "|      ro|\n",
      "|      tl|\n",
      "|      hu|\n",
      "|      ca|\n",
      "|      ht|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600475534689026049|2022-12-07 14:01:17|AIM spoke to @Ree...|Analyticsindiam|    Bengaluru, India|              15350|               483|            0|      en|[quantumcomputing...|\n",
      "|1600475603202981889|2022-12-07 14:01:33|Micro Focus and J...|     jenna_loup|         Houston, TX|                 97|               102|            0|      en|[sustainability, ...|\n",
      "|1600475677743980544|2022-12-07 14:01:51|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataScientist, J...|\n",
      "|1600475711029989376|2022-12-07 14:01:59|RT @ghostx1010: E...|   falconX_1010|                null|                  3|               203|            0|      en|[MachineLearning,...|\n",
      "|1600475715505373184|2022-12-07 14:02:00|How to Transform ...|   DivergentCIO|         Kansas City|              29734|             28024|            0|      en|[EmergingTech, AI...|\n",
      "|1600475778503696384|2022-12-07 14:02:15|RT @Khulood_Alman...|   HAMDANLAVI89| Hafr Al Batin, KSA.|                225|               458|            0|      en|[Data, AI, Python...|\n",
      "|1600475800909717505|2022-12-07 14:02:20|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataAnalytics, S...|\n",
      "|1600475803912994816|2022-12-07 14:02:21|RT @Khulood_Alman...|  flutterbyamey|        Flutterverse|                855|                22|            0|      en|[Data, AI, Python...|\n",
      "|1600475805641064448|2022-12-07 14:02:22|Six Ways Artifici...|  terence_mills|New York | London...|              16043|              8615|            0|      en|[AI, AIio, BigDat...|\n",
      "|1600476059228524544|2022-12-07 14:03:22|RT @HaroldSinnott...|     Untukmassa|Yogyakarta, Indon...|                100|              1481|            0|      en|[SQL, MachineLear...|\n",
      "|1600475661529133057|2022-12-07 14:01:47|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              43619|              2259|            0|      en|[Data, AI, Python...|\n",
      "|1600476054220857344|2022-12-07 14:03:21|A China-linked na...| HexBuddy127001|                null|                 17|               106|            0|      en|[MachineLearning,...|\n",
      "|1600501676586270721|2022-12-07 15:45:10|Why We Migrated F...|   dataclaudius|           Zürich CH|               3215|              2839|            0|      en|[BigData, Analyti...|\n",
      "|1600501681703342080|2022-12-07 15:45:11|Federated Machine...|          goq7v|                null|               1201|              1200|            0|      en|[BigData, learnin...|\n",
      "|1600540645235605506|2022-12-07 18:20:01|Applications of s...|     ingliguori|         Italia 🇮🇹|              48693|              9137|            0|      en|[DigitalTransform...|\n",
      "|1600524775952379904|2022-12-07 17:16:57|RT @Sheraj99: #Li...|  gavaskart1996|        புதுக்கோட்டை|                354|               301|            0|      en|[Linux, MachineLe...|\n",
      "|1600524782201556997|2022-12-07 17:16:59|The first one, yo...|JoannBr21047226|              Canada|                588|              1864|            0|      en|[FraudDetection, ...|\n",
      "|1600615238977601536|2022-12-07 23:16:25|RT @Eli_Krumova: ...|    Eli_Krumova|                  UK|              31372|             23507|            0|      en|[Python, CheatShe...|\n",
      "|1600615259613851648|2022-12-07 23:16:30|RT @m2mtechconnec...|abhinav_singwal|                null|                206|               898|            0|      en|[VR, AR, Cloud, B...|\n",
      "|1600615273144393746|2022-12-07 23:16:33|RT @Eli_Krumova: ...|      RpatoolsC|                null|                879|                31|            0|      en|[DataScientist, D...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load specific historic version\n",
    "df_timetravel_old = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(\"s3a://twitter/delta\")\n",
    "df_timetravel_old.select(\"language\").distinct().show()\n",
    "df_timetravel_old.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144a895",
   "metadata": {},
   "source": [
    "### 5.5 Überschreiben von neueren Version\n",
    "Überschreibe nun mit der älteren Version die Aktuellste. \n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>df_pasttopresent = (spark\n",
    "                   .read.format(\"delta\").option(\"versionAsOf\", 0).load(\"s3a://twitter/delta\")\n",
    "                   .write.partitionBy(\"language\").mode(\"overwrite\").format(\"delta\").save(\"s3a://twitter/delta\")\n",
    "                   )\n",
    "df = spark.read.format(\"delta\").load(\"s3a://solution/twitter_delta\")\n",
    "df.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e561fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600475534689026049|2022-12-07 14:01:17|AIM spoke to @Ree...|Analyticsindiam|    Bengaluru, India|              15350|               483|            0|      en|[quantumcomputing...|\n",
      "|1600475603202981889|2022-12-07 14:01:33|Micro Focus and J...|     jenna_loup|         Houston, TX|                 97|               102|            0|      en|[sustainability, ...|\n",
      "|1600475677743980544|2022-12-07 14:01:51|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataScientist, J...|\n",
      "|1600475711029989376|2022-12-07 14:01:59|RT @ghostx1010: E...|   falconX_1010|                null|                  3|               203|            0|      en|[MachineLearning,...|\n",
      "|1600475715505373184|2022-12-07 14:02:00|How to Transform ...|   DivergentCIO|         Kansas City|              29734|             28024|            0|      en|[EmergingTech, AI...|\n",
      "|1600475778503696384|2022-12-07 14:02:15|RT @Khulood_Alman...|   HAMDANLAVI89| Hafr Al Batin, KSA.|                225|               458|            0|      en|[Data, AI, Python...|\n",
      "|1600475800909717505|2022-12-07 14:02:20|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              44910|              2259|            0|      en|[DataAnalytics, S...|\n",
      "|1600475803912994816|2022-12-07 14:02:21|RT @Khulood_Alman...|  flutterbyamey|        Flutterverse|                855|                22|            0|      en|[Data, AI, Python...|\n",
      "|1600475805641064448|2022-12-07 14:02:22|Six Ways Artifici...|  terence_mills|New York | London...|              16043|              8615|            0|      en|[AI, AIio, BigDat...|\n",
      "|1600476059228524544|2022-12-07 14:03:22|RT @HaroldSinnott...|     Untukmassa|Yogyakarta, Indon...|                100|              1481|            0|      en|[SQL, MachineLear...|\n",
      "|1600475661529133057|2022-12-07 14:01:47|RT @Khulood_Alman...| Khulood_Almani|Kingdom of Saudi ...|              43619|              2259|            0|      en|[Data, AI, Python...|\n",
      "|1600476054220857344|2022-12-07 14:03:21|A China-linked na...| HexBuddy127001|                null|                 17|               106|            0|      en|[MachineLearning,...|\n",
      "|1600501676586270721|2022-12-07 15:45:10|Why We Migrated F...|   dataclaudius|           Zürich CH|               3215|              2839|            0|      en|[BigData, Analyti...|\n",
      "|1600501681703342080|2022-12-07 15:45:11|Federated Machine...|          goq7v|                null|               1201|              1200|            0|      en|[BigData, learnin...|\n",
      "|1600540645235605506|2022-12-07 18:20:01|Applications of s...|     ingliguori|         Italia 🇮🇹|              48693|              9137|            0|      en|[DigitalTransform...|\n",
      "|1600524775952379904|2022-12-07 17:16:57|RT @Sheraj99: #Li...|  gavaskart1996|        புதுக்கோட்டை|                354|               301|            0|      en|[Linux, MachineLe...|\n",
      "|1600524782201556997|2022-12-07 17:16:59|The first one, yo...|JoannBr21047226|              Canada|                588|              1864|            0|      en|[FraudDetection, ...|\n",
      "|1600615238977601536|2022-12-07 23:16:25|RT @Eli_Krumova: ...|    Eli_Krumova|                  UK|              31372|             23507|            0|      en|[Python, CheatShe...|\n",
      "|1600615259613851648|2022-12-07 23:16:30|RT @m2mtechconnec...|abhinav_singwal|                null|                206|               898|            0|      en|[VR, AR, Cloud, B...|\n",
      "|1600615273144393746|2022-12-07 23:16:33|RT @Eli_Krumova: ...|      RpatoolsC|                null|                879|                31|            0|      en|[DataScientist, D...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write old version back as latest\n",
    "df_pasttopresent = (spark\n",
    "                   .read.format(\"delta\").option(\"versionAsOf\", 0).load(\"s3a://twitter/delta\")\n",
    "                   .write.partitionBy(\"language\").mode(\"overwrite\").format(\"delta\").save(\"s3a://twitter/delta\")\n",
    "                   )\n",
    "df = spark.read.format(\"delta\").load(\"s3a://solution/twitter_delta\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde3106",
   "metadata": {},
   "source": [
    "### 5.6 Zurück in die Zukunft\n",
    "Kehre zurück zum aktuellsten Timestamp, indem `timestampAsOf`anstelle von `versionAsOf`verwenden und einem aktuellen timestamp, anstelle der Versionsnummer.\n",
    "<br>\n",
    "<br>\n",
    "<details>\n",
    "<summary> &#8964 Lösung </summary>\n",
    "<p>\n",
    "<code>f_b2future = (spark\n",
    "                .read.format(\"delta\").option(\"timestampAsOf\", \"\\<aktuellsten Stand\\>\").load(\"s3a://twitter/delta\")\n",
    "               )\n",
    "f_b2future.show()</code>\n",
    "</details>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8be4272d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|           tweet_id|         created_at|       tweet_message|      user_name|       user_location|user_follower_count|user_friends_count|retweet_count|language|            hashtags|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "|1600589057381306401|2022-12-07 21:32:23|@EstelaMandela @b...| Khulood_Almani|Kingdom of Saudi ...|              43586|              2261|            0|      en|[AI, Python, Data...|\n",
      "|1600525331085295616|2022-12-07 17:19:09|Free Udemy Certif...|       mikejo_m|                null|                 12|                 4|            0|      en|[Developers, DEVC...|\n",
      "|1600501676586270721|2022-12-07 15:45:10|Why We Migrated F...|   dataclaudius|           Zürich CH|               3215|              2839|            0|      en|[BigData, Analyti...|\n",
      "|1600832825015513089|2022-12-08 13:41:02|@enilev @Cointele...| Khulood_Almani|Kingdom of Saudi ...|              42057|              2262|            0|      en|[Metaverse, Web3,...|\n",
      "|1600701823567945728|2022-12-08 05:00:28|The Non-Programme...|    gp_pulipaka|   Redondo Beach, CA|             132870|             21261|            0|      en|[Programming, Big...|\n",
      "|1600503754817736707|2022-12-07 15:53:25|Colorado Rockies ...|    IainLJBrown|              Marlow|             113804|             96748|            0|      en|[ArtificialIntell...|\n",
      "|1600578334731038720|2022-12-07 20:49:46|https://t.co/Uzjc...|   chidambara09|Mysore & 𝗕𝗘𝗥𝗟...|              11093|                13|            0|      en|[TvTime, movieS, ...|\n",
      "|1600807412277075971|2022-12-08 12:00:03|RT @ValueCoders: ...|  RobotConsumer|                null|               4018|                36|            0|      en|[MachineLearning,...|\n",
      "|1600524901261123586|2022-12-07 17:17:27|https://t.co/gOsg...|algorithmchurch|                null|                214|                74|            0|      en|[AlgorithmChurch,...|\n",
      "|1600729365129482242|2022-12-08 06:49:55|Do #AutonomousVeh...|   PinakiLaskar|19.134884, 72.810591|               2668|               543|            0|      en|[AutonomousVehicl...|\n",
      "|1600586174002647040|2022-12-07 21:20:55|RT @Khulood_Alman...|      alffiguer|      Estados Unidos|                202|              1103|            0|      en|[DataManagement, ...|\n",
      "|1600586192189198341|2022-12-07 21:21:00|#SQL Cheat Sheet!...|      AI_Advice|Havre de Grace, M...|               9063|              9132|            0|      en|[SQL, 5G, 100Days...|\n",
      "|1600610727840157696|2022-12-07 22:58:30|@Marileewoodwar2 ...|SAMUELS02077409|                null|                  1|                15|            0|      en|[Airdrop, DataSci...|\n",
      "|1600477256266256386|2022-12-07 14:08:07|EU hosts $400,000...|  PDH_Metaverse|                 UK |              11996|             10191|            0|      en|[Metaverse, Web3,...|\n",
      "|1600524814795804672|2022-12-07 17:17:06|RT @BDAnalyticsne...|  gavaskart1996|        புதுக்கோட்டை|                354|               301|            0|      en|[BigData, Analyti...|\n",
      "|1600799103914594304|2022-12-08 11:27:02|RT @PawanSomanchi...|  NINJAGOHTESYT|     ,estados unidos|                808|              4609|            0|      en|           [BigData]|\n",
      "|1600531934295298049|2022-12-07 17:45:24|#Infographic: 11 ...| EnFuseSolution|       Mumbai, India|                704|               788|            0|      en|[Infographic, Mac...|\n",
      "|1600759853815058434|2022-12-08 08:51:04|Free Udemy Certif...|    LexiBiancia|                null|                  6|                 0|            0|      en|[Developers, DEVC...|\n",
      "|1600590862614159361|2022-12-07 21:39:33|RT @gp_pulipaka: ...|1000dayscodingb|                null|                717|                 1|            0|      en|[BigData, Analyti...|\n",
      "|1600606290463625224|2022-12-07 22:40:52|@sonu_monika @dan...| Khulood_Almani|Kingdom of Saudi ...|              43584|              2261|            0|      en|[Data, strategy, ...|\n",
      "+-------------------+-------------------+--------------------+---------------+--------------------+-------------------+------------------+-------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_b2future = (spark\n",
    "                .read.format(\"delta\").option(\"timestampAsOf\", \"2022-12-08 16:37:54\").load(\"s3a://twitter/delta\")\n",
    "               )\n",
    "f_b2future.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5df865",
   "metadata": {},
   "source": [
    "# 6. Ausschalten der Spark-App\n",
    "**Bitte schließe am Ende die Spark-App wieder mit dem folgenden Befehl `spark.stop()`, wenn du fertig mit der Bearbeitung der Aufgaben bist.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfdb31e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/08 16:32:34 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb598b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
