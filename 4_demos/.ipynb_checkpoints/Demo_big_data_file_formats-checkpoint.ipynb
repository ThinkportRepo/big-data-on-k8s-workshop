{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610d267c",
   "metadata": {},
   "source": [
    "# Demo and Comparission of Big Data File Formats\n",
    "\n",
    "## 1. CSV and JSON\n",
    "Old dat formats that are not designed for big data and scaling  \n",
    "**Typical feature:** humand readable\n",
    "\n",
    "## 2. Avro, OCR, Parquet\n",
    "First generation of special big data formats that allow fast writes, fast reads or both  \n",
    "**Typical features:** splittable, compressible, data skipping and predicat pushdown, data schema inclueded\n",
    "\n",
    "\n",
    "\n",
    "## 3. Delta, Iceberg, Hudi\n",
    "Latest generation of big data format that support ACID transaction, audit save transaction logs and time travel  \n",
    "**Typical features:** enhancing first generation format with additonal meta data and read/write procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a3b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Laden aller relevate Module\n",
    "#################################################################################\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from delta import *\n",
    "import delta\n",
    "\n",
    "# use 95% of the screen for jupyter cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }<style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e1e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for local usage pip install delta-spark\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars\", \"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f7c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-thinkport.fritz.box:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb5386b3e20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27495f26",
   "metadata": {},
   "source": [
    "## Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b8b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ create new dataframe and show schema and data\n",
      "################################################\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+\n",
      "|id |account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|2  |alex   |2019-02-01    |1500   |\n",
      "|3  |alex   |2019-03-01    |1700   |\n",
      "|1  |alex   |2019-01-01    |1000   |\n",
      "|4  |maria  |2020-01-01    |5000   |\n",
      "+---+-------+--------------+-------+\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|id |account|dt_transaction|balance|new          |\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|1  |otto   |2019-10-01    |4444   |neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "account_data1 = [\n",
    "    (1,\"alex\",\"2019-01-01\",1000),\n",
    "    (2,\"alex\",\"2019-02-01\",1500),\n",
    "    (3,\"alex\",\"2019-03-01\",1700),\n",
    "    (4,\"maria\",\"2020-01-01\",5000)\n",
    "    ]\n",
    "\n",
    "account_data2 = [\n",
    "    (1,\"alex\",\"2019-03-01\",3300),\n",
    "    (2,\"peter\",\"2021-01-01\",100)\n",
    "    ]\n",
    "\n",
    "account_data3 = [\n",
    "    (1,\"otto\",\"2019-10-01\",4444,\"neue Spalte 1\")\n",
    "]\n",
    "\n",
    "schema = [\"id\",\"account\",\"dt_transaction\",\"balance\"]\n",
    "schema3 = [\"id\",\"account\",\"dt_transaction\",\"balance\",\"new\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data=account_data1, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df2 = spark.createDataFrame(data=account_data2, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df3 = spark.createDataFrame(data=account_data3, schema = schema3).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "\n",
    "print(\"++ create new dataframe and show schema and data\")\n",
    "print(\"################################################\")\n",
    "\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fe705",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "916ad0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_csv=(df1\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9d2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n",
      "part-00001-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n",
      "part-00002-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15fb71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: output/csv/part-00000-9414046c-9453-4865-861e-120d6f5b7468-c000.csv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/csv/part-00000-9414046c-9453-4865-861e-120d6f5b7468-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f31d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5a5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a771362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n",
      "part-00000-9575e102-7c59-484a-b228-3ff0c218e96e-c000.csv\r\n",
      "part-00001-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n",
      "part-00002-5d0e1e96-96dd-4ba5-987f-360613bc7cb6-c000.csv\r\n",
      "part-00002-9575e102-7c59-484a-b228-3ff0c218e96e-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fd06f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  1| otto|2019-10-01|4444|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b3038",
   "metadata": {},
   "source": [
    "* kein Schema (Typen)\n",
    "* kein anfügen neuer Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bcbfa",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e368413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_json=(df1\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/json\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9898f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-99215b3a-5830-466d-b6d4-2bb6067e9b13-c000.json\r\n",
      "part-00001-99215b3a-5830-466d-b6d4-2bb6067e9b13-c000.json\r\n",
      "part-00002-99215b3a-5830-466d-b6d4-2bb6067e9b13-c000.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba7f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: output/json/part-00000-9ccd28b9-1b94-4edb-bb20-2b600c5e56d2-c000.json: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/json/part-00000-9ccd28b9-1b94-4edb-bb20-2b600c5e56d2-c000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7506f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/json\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba940d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account: string (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- dt_transaction: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|account|balance|dt_transaction| id|          new|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|   alex|   1500|    2019-02-01|  2|         null|\n",
      "|   alex|   1700|    2019-03-01|  3|         null|\n",
      "|   otto|   4444|    2019-10-01|  1|neue Spalte 1|\n",
      "|  maria|   5000|    2020-01-01|  4|         null|\n",
      "|   alex|   1000|    2019-01-01|  1|         null|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"json\").load(\"output/json\")\n",
    "\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad580792",
   "metadata": {},
   "source": [
    "* Kein Schema\n",
    "* Neue Spalten werden als neues Attribut hinzugefügt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e8bb0",
   "metadata": {},
   "source": [
    "## Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44777375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_avro=(df1\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d82f2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-e96ab2a8-02b2-4c6e-9060-cf1a60854dcd-c000.avro\r\n",
      "part-00001-e96ab2a8-02b2-4c6e-9060-cf1a60854dcd-c000.avro\r\n",
      "part-00002-e96ab2a8-02b2-4c6e-9060-cf1a60854dcd-c000.avro\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/avro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e80adfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: output/avro/part-00000-b6598991-fdff-423a-a94e-bd13548803e3-c000.avro: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/avro/part-00000-b6598991-fdff-423a-a94e-bd13548803e3-c000.avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adbff566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9abf63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_avro=(df3\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac46af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "|  2|   alex|    2019-02-01|   1500|         null|\n",
      "|  3|   alex|    2019-03-01|   1700|         null|\n",
      "|  4|  maria|    2020-01-01|   5000|         null|\n",
      "|  1|   alex|    2019-01-01|   1000|         null|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f9beb",
   "metadata": {},
   "source": [
    "* Schema erhalten\n",
    "* Schema evolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de295",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb546000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_parquet=(df1\n",
    "           .write\n",
    "           .partitionBy(\"account\")\n",
    "           .format(\"parquet\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/parquet\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49b6d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS      \u001b[34maccount=alex\u001b[m\u001b[m  \u001b[34maccount=maria\u001b[m\u001b[m\n",
      "----------------------------\n",
      "part-00000-a1225adc-0d32-4d93-af7c-26ae1bbd0f85.c000.snappy.parquet\n",
      "part-00001-a1225adc-0d32-4d93-af7c-26ae1bbd0f85.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls  output/parquet/\n",
    "!echo \"----------------------------\"\n",
    "!ls output/parquet/account=alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e99e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR1\u0015\u0000\u0015\u001c",
      "\u0015 ,\u0015\u0002\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000e4\u0002\u0000\u0000\u0000\u0003\u0001\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0000\u0015\u0014\u0015\u0018,\u0015\u0002\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\u0004�E\u0000\u0000\u0018\u0004�E\u0000\u0000\u0016\u0000(\u0004�E\u0000\u0000\u0018\u0004�E\u0000\u0000\u0000\u0000\u0000\r\n",
      "$\u0002\u0000\u0000\u0000\u0003\u0001�E\u0000\u0000\u0015\u0000\u0015\u001c",
      "\u0015 ,\u0015\u0002\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000e4\u0002\u0000\u0000\u0000\u0003\u0001�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0002\u0019LH\f",
      "spark_schema\u0015\u0006\u0000\u0015\u0004%\u0002\u0018\u0002id\u0000\u0015\u0002%\u0002\u0018\u000edt_transaction%\f",
      "\u0000\u0015\u0004%\u0002\u0018\u0007balance\u0000\u0016\u0002\u0019\u001c",
      "\u0019<&\b\u001c",
      "\u0015\u0004\u00195\u0000\b\u0006\u0019\u0018\u0002id\u0015\u0002\u0016\u0002\u0016�\u0001\u0016�\u0001&\b<\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&�\u0001\u001c",
      "\u0015\u0002\u00195\u0000\b\u0006\u0019\u0018\u000edt_transaction\u0015\u0002\u0016\u0002\u0016n\u0016r&�\u0001<\u0018\u0004�E\u0000\u0000\u0018\u0004�E\u0000\u0000\u0016\u0000(\u0004�E\u0000\u0000\u0018\u0004�E\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&�\u0002\u001c",
      "\u0015\u0004\u00195\u0000\b\u0006\u0019\u0018\u0007balance\u0015\u0002\u0016\u0002\u0016�\u0001\u0016�\u0001&�\u0002<\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000\u0016�\u0003\u0016\u0002\u0000\u0019,\u0018\u0018org.apache.spark.version\u0018\u00053.1.2\u0000\u0018)org.apache.spark.sql.parquet.row.metadata\u0018�\u0001{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"dt_transaction\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"balance\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}\u0000\u0018Jparquet-mr version 1.10.1 (build a89df8f9932b6ef6633d06069e50c9b7970bebd1)\u0019<\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u0000�\u0002\u0000\u0000PAR1"
     ]
    }
   ],
   "source": [
    "! cat output/parquet/account=alex/part-00001-a1225adc-0d32-4d93-af7c-26ae1bbd0f85.c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae7767",
   "metadata": {},
   "source": [
    "## Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21a69cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df1\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9c789ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m_delta_log\u001b[m\u001b[m\n",
      "part-00000-77b4d015-7026-45bf-9dcd-b32568c95027-c000.snappy.parquet\n",
      "part-00001-9179f41e-35b6-4c46-8ea7-e0c799253d81-c000.snappy.parquet\n",
      "part-00002-c9ae5670-0f60-4884-9a9c-042ff1b850c5-c000.snappy.parquet\n",
      "-------------------------------------------------------------------\n",
      "00000000000000000000.json\n",
      "{\"commitInfo\":{\"timestamp\":1670096258965,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"3\",\"numOutputBytes\":\"3527\",\"numOutputRows\":\"4\"}}}\n",
      "{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}\n",
      "{\"metaData\":{\"id\":\"27f09a67-4291-473a-ab45-c0e74212b17e\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"account\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"dt_transaction\\\",\\\"type\\\":\\\"date\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"balance\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1670096255025}}\n",
      "{\"add\":{\"path\":\"part-00000-77b4d015-7026-45bf-9dcd-b32568c95027-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1202,\"modificationTime\":1670096255000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00001-9179f41e-35b6-4c46-8ea7-e0c799253d81-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1157,\"modificationTime\":1670096255000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00002-c9ae5670-0f60-4884-9a9c-042ff1b850c5-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1168,\"modificationTime\":1670096255000,\"dataChange\":true}}\n"
     ]
    }
   ],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "! cat output/delta/_delta_log/00000000000000000000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3ccb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df2\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )\n",
    "\n",
    "write_delta=(df3\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .option(\"mergeSchema\", \"true\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5bf92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m_delta_log\u001b[m\u001b[m\n",
      "part-00000-0bcd01b3-9af1-486f-b943-df7dc734dee8-c000.snappy.parquet\n",
      "part-00000-7753aa63-d823-4a40-a695-6ba62b86f124-c000.snappy.parquet\n",
      "part-00000-77b4d015-7026-45bf-9dcd-b32568c95027-c000.snappy.parquet\n",
      "part-00000-843ff904-14e8-4e05-9e03-eabdd6bf5263-c000.snappy.parquet\n",
      "part-00000-ee0edf8a-0ca4-4953-8988-bd48d65a5ef3-c000.snappy.parquet\n",
      "part-00000-f7177a2d-53b2-456a-97da-e2d3093f01e8-c000.snappy.parquet\n",
      "part-00001-6bce0058-02b2-4a78-a34f-68a24ce5c0b2-c000.snappy.parquet\n",
      "part-00001-9179f41e-35b6-4c46-8ea7-e0c799253d81-c000.snappy.parquet\n",
      "part-00002-181cb71b-f5de-46eb-ac57-4838617ad4b4-c000.snappy.parquet\n",
      "part-00002-19d3d12a-be62-45aa-a46d-0752c585f3da-c000.snappy.parquet\n",
      "part-00002-2e758d82-3005-46f2-8004-f5d34e52f70f-c000.snappy.parquet\n",
      "part-00002-66584e15-fff8-4ce7-98f0-c0c2f0d31de5-c000.snappy.parquet\n",
      "part-00002-8ba77af9-f44a-42b2-8ab1-0f0c3047957c-c000.snappy.parquet\n",
      "part-00002-c9ae5670-0f60-4884-9a9c-042ff1b850c5-c000.snappy.parquet\n",
      "-------------------------------------------------------------------\n",
      "00000000000000000000.json 00000000000000000002.json 00000000000000000004.json\n",
      "00000000000000000001.json 00000000000000000003.json 00000000000000000005.json\n"
     ]
    }
   ],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "#! cat output/delta/_delta_log/00000000000000000005.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7bbd5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"output/delta\")\n",
    "\n",
    "fullHistoryDF = deltaTable.history()    # get the full history of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "083fc105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|version|readVersion|          timestamp|userId|operation| operationParameters|    operationMetrics|userMetadata|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|      7|          6|2022-12-03 20:47:09|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 2, n...|        null|\n",
      "|      6|          5|2022-12-03 20:47:06|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      5|          4|2022-12-03 20:45:58|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      4|          3|2022-12-03 20:45:56|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      3|          2|2022-12-03 20:45:10|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      2|          1|2022-12-03 20:44:59|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 3, n...|        null|\n",
      "|      1|          0|2022-12-03 20:40:33|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      0|       null|2022-12-03 20:37:39|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 3, n...|        null|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullHistoryDF.select(\"version\",\"readVersion\",\"timestamp\",\"userId\",\"operation\",\"operationParameters\",\"operationMetrics\",\"userMetadata\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02c8f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "|  3|   alex|    2019-03-01|   1700|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"output/delta\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9aba1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "|  2|   alex|    2019-02-01|   1500|         null|\n",
      "|  3|   alex|    2019-03-01|   1700|         null|\n",
      "|  2|  peter|    2021-01-01|    100|         null|\n",
      "|  2|  peter|    2021-01-01|    100|         null|\n",
      "|  4|  maria|    2020-01-01|   5000|         null|\n",
      "|  2|  peter|    2021-01-01|    100|         null|\n",
      "|  1|   alex|    2019-01-01|   1000|         null|\n",
      "|  1|   alex|    2019-03-01|   3300|         null|\n",
      "|  1|   alex|    2019-03-01|   3300|         null|\n",
      "|  1|   alex|    2019-03-01|   3300|         null|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", 6).load(\"output/delta\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438fe27",
   "metadata": {},
   "source": [
    "* Schema\n",
    "* Schema evolution\n",
    "* Transaction Log\n",
    "* Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11faea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
