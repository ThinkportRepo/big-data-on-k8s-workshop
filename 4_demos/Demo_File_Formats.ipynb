{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610d267c",
   "metadata": {},
   "source": [
    "# Demo and Comparission of Big Data File Formats\n",
    "This Notebook runs only on a local Spark Environment, not on Kubernetes\n",
    "\n",
    "## 1. CSV and JSON\n",
    "Old dat formats that are not designed for big data and scaling  \n",
    "**Typical feature:** humand readable\n",
    "\n",
    "## 2. Avro, OCR, Parquet\n",
    "First generation of special big data formats that allow fast writes, fast reads or both  \n",
    "**Typical features:** splittable, compressible, data skipping and predicat pushdown, data schema inclueded\n",
    "\n",
    "\n",
    "\n",
    "## 3. Delta, Iceberg, Hudi\n",
    "Latest generation of big data format that support ACID transaction, audit save transaction logs and time travel  \n",
    "**Typical features:** enhancing first generation format with additonal meta data and read/write procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a3b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Laden aller relevate Module\n",
    "#################################################################################\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from delta import *\n",
    "import delta\n",
    "\n",
    "# use 95% of the screen for jupyter cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }<style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e1e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for local usage pip install delta-spark\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars\", \"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f7c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-thinkport.fritz.box:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa580e0be20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27495f26",
   "metadata": {},
   "source": [
    "## Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b8b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ create new dataframe and show schema and data\n",
      "################################################\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+\n",
      "|id |account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|2  |alex   |2019-02-01    |1500   |\n",
      "|3  |alex   |2019-03-01    |1700   |\n",
      "|1  |alex   |2019-01-01    |1000   |\n",
      "|4  |maria  |2020-01-01    |5000   |\n",
      "+---+-------+--------------+-------+\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|id |account|dt_transaction|balance|new          |\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|1  |otto   |2019-10-01    |4444   |neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initial daten\n",
    "account_data1 = [\n",
    "    (1,\"alex\",\"2019-01-01\",1000),\n",
    "    (2,\"alex\",\"2019-02-01\",1500),\n",
    "    (3,\"alex\",\"2019-03-01\",1700),\n",
    "    (4,\"maria\",\"2020-01-01\",5000)\n",
    "    ]\n",
    "\n",
    "# update mit Änderung und neuem Datensat\n",
    "account_data2 = [\n",
    "    (1,\"alex\",\"2019-03-01\",3300),\n",
    "    (2,\"peter\",\"2021-01-01\",100)\n",
    "    ]\n",
    "\n",
    "# Update mit neuer Spalte\n",
    "account_data3 = [\n",
    "    (1,\"otto\",\"2019-10-01\",4444,\"neue Spalte 1\")\n",
    "]\n",
    "\n",
    "schema = [\"id\",\"account\",\"dt_transaction\",\"balance\"]\n",
    "schema3 = [\"id\",\"account\",\"dt_transaction\",\"balance\",\"new\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data=account_data1, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df2 = spark.createDataFrame(data=account_data2, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df3 = spark.createDataFrame(data=account_data3, schema = schema3).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "\n",
    "print(\"++ create new dataframe and show schema and data\")\n",
    "print(\"################################################\")\n",
    "\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fe705",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916ad0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_csv=(df1\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9d2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n",
      "part-00001-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n",
      "part-00002-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15fb71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,alex,2019-02-01,1500\r\n",
      "3,alex,2019-03-01,1700\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/csv/part-00000-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f31d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5a5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a771362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-c00067e8-489a-4d83-a10d-8150464ebe13-c000.csv\r\n",
      "part-00000-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n",
      "part-00001-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n",
      "part-00002-c00067e8-489a-4d83-a10d-8150464ebe13-c000.csv\r\n",
      "part-00002-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349331cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,maria,2020-01-01,5000\r\n"
     ]
    }
   ],
   "source": [
    "!cat output/csv/part-00002-cafca750-9bea-456b-91bb-3b4ec709e4ff-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fd06f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  1| otto|2019-10-01|4444|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b3038",
   "metadata": {},
   "source": [
    "* kein Schema (Typen)\n",
    "* kein anfügen neuer Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bcbfa",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e368413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_json=(df1\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/json\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9898f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-4f747c35-4c02-45ee-ab3e-314b2f10d233-c000.json\r\n",
      "part-00001-4f747c35-4c02-45ee-ab3e-314b2f10d233-c000.json\r\n",
      "part-00002-4f747c35-4c02-45ee-ab3e-314b2f10d233-c000.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba7f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":2,\"account\":\"alex\",\"dt_transaction\":\"2019-02-01\",\"balance\":1500}\r\n",
      "{\"id\":3,\"account\":\"alex\",\"dt_transaction\":\"2019-03-01\",\"balance\":1700}\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/json/part-00000-4f747c35-4c02-45ee-ab3e-314b2f10d233-c000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7506f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/json\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba940d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account: string (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- dt_transaction: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|account|balance|dt_transaction| id|          new|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|   alex|   1500|    2019-02-01|  2|         null|\n",
      "|   alex|   1700|    2019-03-01|  3|         null|\n",
      "|   otto|   4444|    2019-10-01|  1|neue Spalte 1|\n",
      "|  maria|   5000|    2020-01-01|  4|         null|\n",
      "|   alex|   1000|    2019-01-01|  1|         null|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"json\").load(\"output/json\")\n",
    "\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad580792",
   "metadata": {},
   "source": [
    "* Kein Schema\n",
    "* Neue Spalten werden als neues Attribut hinzugefügt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e8bb0",
   "metadata": {},
   "source": [
    "## Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44777375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_avro=(df1\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82f2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-4ee4c000-eb1f-4f41-a36d-47d5bc8e9484-c000.avro\r\n",
      "part-00001-4ee4c000-eb1f-4f41-a36d-47d5bc8e9484-c000.avro\r\n",
      "part-00002-4ee4c000-eb1f-4f41-a36d-47d5bc8e9484-c000.avro\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/avro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc0cf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj\u0001\u0006\u0016avro.schema�\u0003{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"id\",\"type\":[\"long\",\"null\"]},{\"name\":\"account\",\"type\":[\"string\",\"null\"]},{\"name\":\"dt_transaction\",\"type\":[{\"type\":\"int\",\"logicalType\":\"date\"},\"null\"]},{\"name\":\"balance\",\"type\":[\"long\",\"null\"]}]}0org.apache.spark.version\r\n",
      "3.1.2\u0014avro.codec\f",
      "snappy\u0000�-���\u001d",
      "\u0002 \r\n",
      "B֨\u0017\u0004a<\u0004H\u001e",
      "t\u0000\u0004\u0000\balex\u0000��\u0002\u0000�\u0017\u0000\u0006\u0000\balex\u0000Ș\u0002\u0000�\u001a3����-���\u001d",
      "\u0002 \r\n",
      "B֨\u0017\u0004a<"
     ]
    }
   ],
   "source": [
    "! cat output/avro/part-00000-4ee4c000-eb1f-4f41-a36d-47d5bc8e9484-c000.avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac72f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b1e0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_avro=(df3\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70570799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "|  2|   alex|    2019-02-01|   1500|         null|\n",
      "|  3|   alex|    2019-03-01|   1700|         null|\n",
      "|  4|  maria|    2020-01-01|   5000|         null|\n",
      "|  1|   alex|    2019-01-01|   1000|         null|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1054d",
   "metadata": {},
   "source": [
    "* Schema erhalten\n",
    "* Schema evolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de295",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb546000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_parquet=(df1\n",
    "           .write\n",
    "           .partitionBy(\"account\")\n",
    "           .format(\"parquet\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/parquet\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bbba040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "|  3|   alex|    2019-03-01|   1700|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49b6d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS      \u001b[34maccount=alex\u001b[m\u001b[m  \u001b[34maccount=maria\u001b[m\u001b[m\n",
      "----------------------------\n",
      "part-00000-d2c469a4-2fe0-44e9-a6e1-b65a59750105.c000.snappy.parquet\n",
      "part-00001-d2c469a4-2fe0-44e9-a6e1-b65a59750105.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls  output/parquet/\n",
    "!echo \"----------------------------\"\n",
    "!ls output/parquet/account=alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e99e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR1\u0015\u0000\u0015,\u0015.,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0014\u0002\u0000\u0000\u0000\u0003\u0003\u0001\u0006,\u0000\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0000\u0015\u001c",
      "\u0015 ,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0016\u0000(\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0000\u0000\u0000\u000e4\u0002\u0000\u0000\u0000\u0003\u0003\bF\u0000\u0000$F\u0000\u0000\u0015\u0000\u0015,\u00150,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c",
      "\u0018\b�\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b�\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016T\u0002\u0000\u0000\u0000\u0003\u0003�\u0005\u0000\u0000\u0000\u0000\u0000\u0000�\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0002\u0019LH\f",
      "spark_schema\u0015\u0006\u0000\u0015\u0004%\u0002\u0018\u0002id\u0000\u0015\u0002%\u0002\u0018\u000edt_transaction%\f",
      "\u0000\u0015\u0004%\u0002\u0018\u0007balance\u0000\u0016\u0004\u0019\u001c",
      "\u0019<&\b\u001c",
      "\u0015\u0004\u00195\u0006\u0000\b\u0019\u0018\u0002id\u0015\u0002\u0016\u0004\u0016�\u0001\u0016�\u0001&\b<\u0018\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&�\u0001\u001c",
      "\u0015\u0002\u00195\u0006\u0000\b\u0019\u0018\u000edt_transaction\u0015\u0002\u0016\u0004\u0016v\u0016z&�\u0001<\u0018\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0016\u0000(\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&�\u0002\u001c",
      "\u0015\u0004\u00195\u0006\u0000\b\u0019\u0018\u0007balance\u0015\u0002\u0016\u0004\u0016�\u0001\u0016�\u0001&�\u0002<\u0018\b�\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b�\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b�\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000\u0016�\u0003\u0016\u0004\u0000\u0019,\u0018\u0018org.apache.spark.version\u0018\u00053.1.2\u0000\u0018)org.apache.spark.sql.parquet.row.metadata\u0018�\u0001{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"dt_transaction\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"balance\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}\u0000\u0018Jparquet-mr version 1.10.1 (build a89df8f9932b6ef6633d06069e50c9b7970bebd1)\u0019<\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u001c",
      "\u0000\u0000\u0000�\u0002\u0000\u0000PAR1"
     ]
    }
   ],
   "source": [
    "! cat output/parquet/account=alex/part-00000-d2c469a4-2fe0-44e9-a6e1-b65a59750105.c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e00a1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+-------+\n",
      "| id|dt_transaction|balance|account|\n",
      "+---+--------------+-------+-------+\n",
      "|  2|    2019-02-01|   1500|   alex|\n",
      "|  3|    2019-03-01|   1700|   alex|\n",
      "|  1|    2019-01-01|   1000|   alex|\n",
      "+---+--------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_parquet=spark.read.format(\"parquet\").load(\"output/parquet/\").filter(col(\"account\")==\"alex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eadd53c",
   "metadata": {},
   "source": [
    "## Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513d213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df1\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .option(\"mergeSchema\", \"true\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70cd6f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m_delta_log\u001b[m\u001b[m\n",
      "part-00000-e9b95674-8715-499f-bac3-89982b31cc30-c000.snappy.parquet\n",
      "part-00001-005e4570-4e0b-4446-a401-5003d73a31d8-c000.snappy.parquet\n",
      "part-00002-13e80cc5-5ace-406d-a5b3-03a4092dd820-c000.snappy.parquet\n",
      "-------------------------------------------------------------------\n",
      "00000000000000000000.json\n",
      "{\"commitInfo\":{\"timestamp\":1679905342316,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"3\",\"numOutputBytes\":\"3527\",\"numOutputRows\":\"4\"}}}\n",
      "{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}\n",
      "{\"metaData\":{\"id\":\"990facb3-96e2-4a90-aa29-e430901a20d3\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"account\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"dt_transaction\\\",\\\"type\\\":\\\"date\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"balance\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1679905336029}}\n",
      "{\"add\":{\"path\":\"part-00000-e9b95674-8715-499f-bac3-89982b31cc30-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1202,\"modificationTime\":1679905336000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00001-005e4570-4e0b-4446-a401-5003d73a31d8-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1157,\"modificationTime\":1679905336000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00002-13e80cc5-5ace-406d-a5b3-03a4092dd820-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1168,\"modificationTime\":1679905336000,\"dataChange\":true}}\n"
     ]
    }
   ],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "! cat output/delta/_delta_log/00000000000000000000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a714c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df2\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8d72dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df3\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .option(\"mergeSchema\", \"true\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5bf92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m_delta_log\u001b[m\u001b[m\n",
      "part-00000-0c5a4784-da0d-4c7c-b061-b295aba553b9-c000.snappy.parquet\n",
      "part-00000-79d8416d-1705-4cb8-ab50-a8d4262884db-c000.snappy.parquet\n",
      "part-00000-e9b95674-8715-499f-bac3-89982b31cc30-c000.snappy.parquet\n",
      "part-00001-005e4570-4e0b-4446-a401-5003d73a31d8-c000.snappy.parquet\n",
      "part-00002-13e80cc5-5ace-406d-a5b3-03a4092dd820-c000.snappy.parquet\n",
      "part-00002-bb100df5-6963-44fa-a92c-8d91c90a2567-c000.snappy.parquet\n",
      "part-00002-dba1b47f-e13c-41db-9135-12dfaea3ad84-c000.snappy.parquet\n",
      "-------------------------------------------------------------------\n",
      "00000000000000000000.json 00000000000000000001.json 00000000000000000002.json\n",
      "{\"commitInfo\":{\"timestamp\":1679905429051,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"readVersion\":1,\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"2\",\"numOutputBytes\":\"2077\",\"numOutputRows\":\"1\"}}}\n",
      "{\"metaData\":{\"id\":\"990facb3-96e2-4a90-aa29-e430901a20d3\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"account\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"dt_transaction\\\",\\\"type\\\":\\\"date\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"balance\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"new\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1679905336029}}\n",
      "{\"add\":{\"path\":\"part-00000-79d8416d-1705-4cb8-ab50-a8d4262884db-c000.snappy.parquet\",\"partitionValues\":{},\"size\":633,\"modificationTime\":1679905426000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00002-bb100df5-6963-44fa-a92c-8d91c90a2567-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1444,\"modificationTime\":1679905426000,\"dataChange\":true}}\n",
      "{\"remove\":{\"path\":\"part-00002-dba1b47f-e13c-41db-9135-12dfaea3ad84-c000.snappy.parquet\",\"deletionTimestamp\":1679905429030,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1168}}\n",
      "{\"remove\":{\"path\":\"part-00002-13e80cc5-5ace-406d-a5b3-03a4092dd820-c000.snappy.parquet\",\"deletionTimestamp\":1679905429041,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1168}}\n",
      "{\"remove\":{\"path\":\"part-00001-005e4570-4e0b-4446-a401-5003d73a31d8-c000.snappy.parquet\",\"deletionTimestamp\":1679905429041,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1157}}\n",
      "{\"remove\":{\"path\":\"part-00000-e9b95674-8715-499f-bac3-89982b31cc30-c000.snappy.parquet\",\"deletionTimestamp\":1679905429041,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1202}}\n",
      "{\"remove\":{\"path\":\"part-00000-0c5a4784-da0d-4c7c-b061-b295aba553b9-c000.snappy.parquet\",\"deletionTimestamp\":1679905429041,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1157}}\n"
     ]
    }
   ],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "! cat output/delta/_delta_log/00000000000000000002.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cb3480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"output/delta\")\n",
    "\n",
    "fullHistoryDF = deltaTable.history()    # get the full history of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac186df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|version|readVersion|          timestamp|userId|operation| operationParameters|    operationMetrics|userMetadata|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|      2|          1|2023-03-27 10:23:49|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 2, n...|        null|\n",
      "|      1|          0|2023-03-27 10:23:34|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      0|       null|2023-03-27 10:22:22|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 3, n...|        null|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullHistoryDF.select(\"version\",\"readVersion\",\"timestamp\",\"userId\",\"operation\",\"operationParameters\",\"operationMetrics\",\"userMetadata\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49f89cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_parquet=spark.read.format(\"delta\").load(\"output/delta/\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc61efc",
   "metadata": {},
   "source": [
    "## Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6617afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versionAsOf\", \"2\").load(\"output/delta\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d249d",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aea3fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  1|   alex|    2019-03-01|   3300|\n",
      "|  2|  peter|    2021-01-01|    100|\n",
      "+---+-------+--------------+-------+\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable2 = DeltaTable.forPath(spark, \"output/delta\")\n",
    "\n",
    "df2.show()\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1688108",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve `new` in UPDATE clause given columns newData.`id`, newData.`account`, newData.`dt_transaction`, newData.`balance`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-2a4132b760f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dt3=(deltaTable2.alias(\"oldData\")\n\u001b[0m\u001b[1;32m      2\u001b[0m       .merge(df2.alias(\"newData\"),\n\u001b[1;32m      3\u001b[0m             \"oldData.account = newData.account AND oldData.dt_transaction = newData.dt_transaction\")\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mwhenMatchedUpdateAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mwhenNotMatchedInsertAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/private/var/folders/23/h45wxwgx36vgndvfmqfwvjn80000gn/T/spark-a174b338-72f4-4626-8af1-657137e8bbdb/userFiles-24000abb-aabb-4c4a-94da-a1453fe767e1/io.delta_delta-core_2.12-1.0.1.jar/delta/tables.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeltaMergeBuilder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomplete\u001b[0m \u001b[0musage\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getMatchedBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve `new` in UPDATE clause given columns newData.`id`, newData.`account`, newData.`dt_transaction`, newData.`balance`"
     ]
    }
   ],
   "source": [
    "dt3=(deltaTable2.alias(\"oldData\")\n",
    "      .merge(df2.alias(\"newData\"),\n",
    "            \"oldData.account = newData.account AND oldData.dt_transaction = newData.dt_transaction\")\n",
    "            .whenMatchedUpdateAll()\n",
    "            .whenNotMatchedInsertAll()\n",
    "      .execute()\n",
    "    )\n",
    "\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e42a0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------+\n",
      "|account|month|sum(balance)|\n",
      "+-------+-----+------------+\n",
      "|   alex|    1|        1000|\n",
      "|   alex|    2|        1500|\n",
      "|   alex|    3|        3300|\n",
      "|  maria|    1|        5000|\n",
      "|  peter|    1|         100|\n",
      "+-------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=(deltaTable2\n",
    "        .toDF()\n",
    "        .withColumn(\"month\",month(col(\"dt_transaction\")))\n",
    "        .groupBy(\"account\",\"month\").agg(sum(\"balance\"))\n",
    "        .sort(\"account\",\"month\")\n",
    "       )\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2db16769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------+\n",
      "|account|month|sum(balance)|\n",
      "+-------+-----+------------+\n",
      "|   alex|    1|        1000|\n",
      "|   alex|    2|        1500|\n",
      "|   alex|    3|        3300|\n",
      "|  maria|    1|        5000|\n",
      "|  peter|    1|         100|\n",
      "+-------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=(spark.read\n",
    "        .format(\"delta\")\n",
    "        .option(\"versionAsOf\", \"1\")\n",
    "        .load(\"output/delta\")\n",
    "        .withColumn(\"month\",month(col(\"dt_transaction\")))\n",
    "        .groupBy(\"account\",\"month\").agg(sum(\"balance\"))\n",
    "        .sort(\"account\",\"month\")\n",
    "       )\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe344799",
   "metadata": {},
   "source": [
    "* Schema\n",
    "* Schema evolution\n",
    "* Transaction Log\n",
    "* Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d11faea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc289a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
