{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610d267c",
   "metadata": {},
   "source": [
    "# Demo and Comparission of Big Data File Formats\n",
    "This Notebook runs only on a local Spark Environment, not on Kubernetes\n",
    "\n",
    "## 1. CSV and JSON\n",
    "Old dat formats that are not designed for big data and scaling  \n",
    "**Typical feature:** humand readable\n",
    "\n",
    "## 2. Avro, OCR, Parquet\n",
    "First generation of special big data formats that allow fast writes, fast reads or both  \n",
    "**Typical features:** splittable, compressible, data skipping and predicat pushdown, data schema inclueded\n",
    "\n",
    "\n",
    "\n",
    "## 3. Delta, Iceberg, Hudi\n",
    "Latest generation of big data format that support ACID transaction, audit save transaction logs and time travel  \n",
    "**Typical features:** enhancing first generation format with additonal meta data and read/write procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a3b58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Laden aller relevate Module\n",
    "#################################################################################\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from delta import *\n",
    "import delta\n",
    "\n",
    "# use 95% of the screen for jupyter cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important; }<style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e1e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first for local usage pip install delta-spark\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars\", \"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\",\"/Users/alor/opt/spark/jars/spark-sql-kafka-0-10_2.12-3.3.1.jar, /Users/alor/opt/spark/jars/kafka-clients-3.3.1.jar, /Users/alor/opt/spark/jars/spark-avro_2.12-3.3.1.jar\")\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27495f26",
   "metadata": {},
   "source": [
    "## Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b8b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++ create new dataframe and show schema and data\n",
      "################################################\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+\n",
      "|id |account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|2  |alex   |2019-02-01    |1500   |\n",
      "|3  |alex   |2019-03-01    |1700   |\n",
      "|1  |alex   |2019-01-01    |1000   |\n",
      "|4  |maria  |2020-01-01    |5000   |\n",
      "+---+-------+--------------+-------+\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|id |account|dt_transaction|balance|new          |\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|1  |otto   |2019-10-01    |4444   |neue Spalte 1|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initial daten\n",
    "account_data1 = [\n",
    "    (1,\"alex\",\"2019-01-01\",1000),\n",
    "    (2,\"alex\",\"2019-02-01\",1500),\n",
    "    (3,\"alex\",\"2019-03-01\",1700),\n",
    "    (4,\"maria\",\"2020-01-01\",5000)\n",
    "    ]\n",
    "\n",
    "# update mit Ã„nderung und neuem Datensat\n",
    "account_data2 = [\n",
    "    (1,\"alex\",\"2019-03-01\",3300),\n",
    "    (2,\"peter\",\"2021-01-01\",100)\n",
    "    ]\n",
    "\n",
    "# Update mit neuer Spalte\n",
    "account_data3 = [\n",
    "    (1,\"otto\",\"2019-10-01\",4444,\"neue Spalte 1\")\n",
    "]\n",
    "\n",
    "schema = [\"id\",\"account\",\"dt_transaction\",\"balance\"]\n",
    "schema3 = [\"id\",\"account\",\"dt_transaction\",\"balance\",\"new\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data=account_data1, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df2 = spark.createDataFrame(data=account_data2, schema = schema).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "df3 = spark.createDataFrame(data=account_data3, schema = schema3).withColumn(\"dt_transaction\",col(\"dt_transaction\").cast(\"date\")).repartition(3)\n",
    "\n",
    "print(\"++ create new dataframe and show schema and data\")\n",
    "print(\"################################################\")\n",
    "\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fe705",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916ad0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_csv=(df1\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9d2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n",
      "part-00001-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n",
      "part-00002-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15fb71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,alex,2019-02-01,1500\r\n",
      "3,alex,2019-03-01,1700\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/csv/part-00000-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f31d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5a5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"csv\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/csv\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a771362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n",
      "part-00000-55792bd8-13d5-468e-93ce-4b9dc132e3c3-c000.csv\r\n",
      "part-00001-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n",
      "part-00002-4f004dc2-afa5-4612-b20a-e077538cd467-c000.csv\r\n",
      "part-00002-55792bd8-13d5-468e-93ce-4b9dc132e3c3-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349331cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,otto,2019-10-01,4444,neue Spalte 1\r\n"
     ]
    }
   ],
   "source": [
    "!cat output/csv/part-00002-55792bd8-13d5-468e-93ce-4b9dc132e3c3-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fd06f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n",
      "+---+-----+----------+----+\n",
      "|_c0|  _c1|       _c2| _c3|\n",
      "+---+-----+----------+----+\n",
      "|  2| alex|2019-02-01|1500|\n",
      "|  3| alex|2019-03-01|1700|\n",
      "|  1| otto|2019-10-01|4444|\n",
      "|  4|maria|2020-01-01|5000|\n",
      "|  1| alex|2019-01-01|1000|\n",
      "+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_csv=spark.read.format(\"csv\").load(\"output/csv\")\n",
    "\n",
    "read_csv.printSchema()\n",
    "read_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b3038",
   "metadata": {},
   "source": [
    "* kein Schema (Typen)\n",
    "* kein anfÃ¼gen neuer Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bcbfa",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e368413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_json=(df1\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/json\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da9898f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-ff1a03b2-b55f-4e7c-940f-c664cdfcd644-c000.json\r\n",
      "part-00001-ff1a03b2-b55f-4e7c-940f-c664cdfcd644-c000.json\r\n",
      "part-00002-ff1a03b2-b55f-4e7c-940f-c664cdfcd644-c000.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba7f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":2,\"account\":\"alex\",\"dt_transaction\":\"2019-02-01\",\"balance\":1500}\r\n",
      "{\"id\":3,\"account\":\"alex\",\"dt_transaction\":\"2019-03-01\",\"balance\":1700}\r\n"
     ]
    }
   ],
   "source": [
    "! cat output/json/part-00000-ff1a03b2-b55f-4e7c-940f-c664cdfcd644-c000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7506f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv=(df3\n",
    "           .write\n",
    "           .format(\"json\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/json\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba940d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account: string (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- dt_transaction: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|account|balance|dt_transaction| id|          new|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "|   alex|   1500|    2019-02-01|  2|         null|\n",
      "|   alex|   1700|    2019-03-01|  3|         null|\n",
      "|   otto|   4444|    2019-10-01|  1|neue Spalte 1|\n",
      "|  maria|   5000|    2020-01-01|  4|         null|\n",
      "|   alex|   1000|    2019-01-01|  1|         null|\n",
      "+-------+-------+--------------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"json\").load(\"output/json\")\n",
    "\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad580792",
   "metadata": {},
   "source": [
    "* Kein Schema\n",
    "* Neue Spalten werden als neues Attribut hinzugefÃ¼gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e8bb0",
   "metadata": {},
   "source": [
    "## Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44777375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_avro=(df1\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d82f2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-3b3b12df-ccb3-42fc-8157-ac9b5431fb2b-c000.avro\r\n",
      "part-00001-3b3b12df-ccb3-42fc-8157-ac9b5431fb2b-c000.avro\r\n",
      "part-00002-3b3b12df-ccb3-42fc-8157-ac9b5431fb2b-c000.avro\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/avro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0cf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj\u0001\u0006\u0016avro.schemaï¿½\u0003{\"type\":\"record\",\"name\":\"topLevelRecord\",\"fields\":[{\"name\":\"id\",\"type\":[\"long\",\"null\"]},{\"name\":\"account\",\"type\":[\"string\",\"null\"]},{\"name\":\"dt_transaction\",\"type\":[{\"type\":\"int\",\"logicalType\":\"date\"},\"null\"]},{\"name\":\"balance\",\"type\":[\"long\",\"null\"]}]}0org.apache.spark.version\r\n",
      "3.1.2\u0014avro.codec\f\n",
      "snappy\u0000D\u001a0\u001e\n",
      "ï¿½\r\n",
      ".\\@6-@!ï¿½&%\u0004H\u001e\n",
      "t\u0000\u0004\u0000\balex\u0000ï¿½ï¿½\u0002\u0000ï¿½\u0017\u0000\u0006\u0000\balex\u0000È˜\u0002\u0000ï¿½\u001a3ï¿½ï¿½ï¿½D\u001a0\u001e\n",
      "ï¿½\r\n",
      ".\\@6-@!ï¿½&%"
     ]
    }
   ],
   "source": [
    "! cat output/avro/part-00000-3b3b12df-ccb3-42fc-8157-ac9b5431fb2b-c000.avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac72f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b1e0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_avro=(df3\n",
    "           .write\n",
    "           .format(\"avro\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/avro\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70570799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- account: string (nullable = true)\n",
      " |-- dt_transaction: date (nullable = true)\n",
      " |-- balance: long (nullable = true)\n",
      " |-- new: string (nullable = true)\n",
      "\n",
      "+---+-------+--------------+-------+-------------+\n",
      "| id|account|dt_transaction|balance|          new|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "|  1|   otto|    2019-10-01|   4444|neue Spalte 1|\n",
      "|  2|   alex|    2019-02-01|   1500|         null|\n",
      "|  3|   alex|    2019-03-01|   1700|         null|\n",
      "|  4|  maria|    2020-01-01|   5000|         null|\n",
      "|  1|   alex|    2019-01-01|   1000|         null|\n",
      "+---+-------+--------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_json=spark.read.format(\"avro\").load(\"output/avro\")\n",
    "read_json.printSchema()\n",
    "read_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b1054d",
   "metadata": {},
   "source": [
    "* Schema erhalten\n",
    "* Schema evolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de295",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb546000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Partitions:\", df1.rdd.getNumPartitions())\n",
    "\n",
    "write_parquet=(df1\n",
    "           .write\n",
    "           .partitionBy(\"account\")\n",
    "           .format(\"parquet\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/parquet\")\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bbba040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "|  3|   alex|    2019-03-01|   1700|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49b6d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS      \u001b[34maccount=alex\u001b[m\u001b[m  \u001b[34maccount=maria\u001b[m\u001b[m\n",
      "----------------------------\n",
      "part-00000-f4019e07-a8c8-499e-a98d-eb75706f3b0f.c000.snappy.parquet\n",
      "part-00001-f4019e07-a8c8-499e-a98d-eb75706f3b0f.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls  output/parquet/\n",
    "!echo \"----------------------------\"\n",
    "!ls output/parquet/account=alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e99e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAR1\u0015\u0000\u0015,\u0015.,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c\n",
      "\u0018\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0014\u0002\u0000\u0000\u0000\u0003\u0003\u0001\u0006,\u0000\u0000\u0000\u0000\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0000\u0015\u001c\n",
      "\u0015 ,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c\n",
      "\u0018\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0016\u0000(\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0000\u0000\u0000\u000e4\u0002\u0000\u0000\u0000\u0003\u0003\bF\u0000\u0000$F\u0000\u0000\u0015\u0000\u0015,\u00150,\u0015\u0004\u0015\u0000\u0015\u0006\u0015\b\u001c\n",
      "\u0018\bï¿½\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\bï¿½\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\bï¿½\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\bï¿½\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016T\u0002\u0000\u0000\u0000\u0003\u0003ï¿½\u0005\u0000\u0000\u0000\u0000\u0000\u0000ï¿½\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0015\u0002\u0019LH\f\n",
      "spark_schema\u0015\u0006\u0000\u0015\u0004%\u0002\u0018\u0002id\u0000\u0015\u0002%\u0002\u0018\u000edt_transaction%\f\n",
      "\u0000\u0015\u0004%\u0002\u0018\u0007balance\u0000\u0016\u0004\u0019\u001c\n",
      "\u0019<&\b\u001c\n",
      "\u0015\u0004\u00195\b\u0000\u0006\u0019\u0018\u0002id\u0015\u0002\u0016\u0004\u0016ï¿½\u0001\u0016ï¿½\u0001&\b<\u0018\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\b\u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0018\b\u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c\n",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&ï¿½\u0001\u001c\n",
      "\u0015\u0002\u00195\b\u0000\u0006\u0019\u0018\u000edt_transaction\u0015\u0002\u0016\u0004\u0016v\u0016z&ï¿½\u0001<\u0018\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0016\u0000(\u0004$F\u0000\u0000\u0018\u0004\bF\u0000\u0000\u0000\u0019\u001c\n",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000&ï¿½\u0002\u001c\n",
      "\u0015\u0004\u00195\b\u0000\u0006\u0019\u0018\u0007balance\u0015\u0002\u0016\u0004\u0016ï¿½\u0001\u0016ï¿½\u0001&ï¿½\u0002<\u0018\bï¿½\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\bï¿½\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000(\bï¿½\u0006\u0000\u0000\u0000\u0000\u0000\u0000\u0018\bï¿½\u0005\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0019\u001c\n",
      "\u0015\u0000\u0015\u0000\u0015\u0002\u0000\u0000\u0000\u0016ï¿½\u0003\u0016\u0004\u0000\u0019,\u0018\u0018org.apache.spark.version\u0018\u00053.1.2\u0000\u0018)org.apache.spark.sql.parquet.row.metadata\u0018ï¿½\u0001{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"dt_transaction\",\"type\":\"date\",\"nullable\":true,\"metadata\":{}},{\"name\":\"balance\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}\u0000\u0018Jparquet-mr version 1.10.1 (build a89df8f9932b6ef6633d06069e50c9b7970bebd1)\u0019<\u001c\n",
      "\u0000\u0000\u001c\n",
      "\u0000\u0000\u001c\n",
      "\u0000\u0000\u0000ï¿½\u0002\u0000\u0000PAR1"
     ]
    }
   ],
   "source": [
    "! cat output/parquet/account=alex/part-00000-f4019e07-a8c8-499e-a98d-eb75706f3b0f.c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e00a1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-------+-------+\n",
      "| id|dt_transaction|balance|account|\n",
      "+---+--------------+-------+-------+\n",
      "|  2|    2019-02-01|   1500|   alex|\n",
      "|  3|    2019-03-01|   1700|   alex|\n",
      "|  1|    2019-01-01|   1000|   alex|\n",
      "+---+--------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_parquet=spark.read.format(\"parquet\").load(\"output/parquet/\").filter(col(\"account\")==\"alex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eadd53c",
   "metadata": {},
   "source": [
    "## Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "513d213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df1\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .option(\"mergeSchema\", \"true\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70cd6f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m_delta_log\u001b[m\u001b[m\n",
      "part-00000-63ddc6e6-20a0-4bce-948f-33896396b51f-c000.snappy.parquet\n",
      "part-00000-8587accb-32ea-493b-9407-4e9cbc1ca156-c000.snappy.parquet\n",
      "part-00000-8888c4f1-214a-4356-a253-57cfc4886df8-c000.snappy.parquet\n",
      "part-00001-4996de49-d113-4690-a72c-ad42da85ebda-c000.snappy.parquet\n",
      "part-00002-0e0a1bc0-c7cd-48e0-811d-b2724c02f387-c000.snappy.parquet\n",
      "part-00002-3e99d576-e3a1-4627-bdcd-3fa0dc6b425b-c000.snappy.parquet\n",
      "part-00002-78a5675b-06af-41b0-a31c-2380898cdad4-c000.snappy.parquet\n",
      "-------------------------------------------------------------------\n",
      "00000000000000000000.json 00000000000000000001.json 00000000000000000002.json\n",
      "{\"commitInfo\":{\"timestamp\":1670243456445,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"readVersion\":1,\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"2\",\"numOutputBytes\":\"2077\",\"numOutputRows\":\"1\"}}}\n",
      "{\"metaData\":{\"id\":\"e4afc96f-1279-482c-906d-ad93c40b2296\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\"type\\\":\\\"struct\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"account\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"dt_transaction\\\",\\\"type\\\":\\\"date\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"balance\\\",\\\"type\\\":\\\"long\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}},{\\\"name\\\":\\\"new\\\",\\\"type\\\":\\\"string\\\",\\\"nullable\\\":true,\\\"metadata\\\":{}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1670243260224}}\n",
      "{\"add\":{\"path\":\"part-00000-8587accb-32ea-493b-9407-4e9cbc1ca156-c000.snappy.parquet\",\"partitionValues\":{},\"size\":633,\"modificationTime\":1670243455000,\"dataChange\":true}}\n",
      "{\"add\":{\"path\":\"part-00002-3e99d576-e3a1-4627-bdcd-3fa0dc6b425b-c000.snappy.parquet\",\"partitionValues\":{},\"size\":1444,\"modificationTime\":1670243455000,\"dataChange\":true}}\n",
      "{\"remove\":{\"path\":\"part-00001-4996de49-d113-4690-a72c-ad42da85ebda-c000.snappy.parquet\",\"deletionTimestamp\":1670243456443,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1157}}\n",
      "{\"remove\":{\"path\":\"part-00002-78a5675b-06af-41b0-a31c-2380898cdad4-c000.snappy.parquet\",\"deletionTimestamp\":1670243456443,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1168}}\n",
      "{\"remove\":{\"path\":\"part-00002-0e0a1bc0-c7cd-48e0-811d-b2724c02f387-c000.snappy.parquet\",\"deletionTimestamp\":1670243456443,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1168}}\n",
      "{\"remove\":{\"path\":\"part-00000-8888c4f1-214a-4356-a253-57cfc4886df8-c000.snappy.parquet\",\"deletionTimestamp\":1670243456443,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1157}}\n",
      "{\"remove\":{\"path\":\"part-00000-63ddc6e6-20a0-4bce-948f-33896396b51f-c000.snappy.parquet\",\"deletionTimestamp\":1670243456443,\"dataChange\":true,\"extendedFileMetadata\":true,\"partitionValues\":{},\"size\":1202}}\n"
     ]
    }
   ],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "! cat output/delta/_delta_log/00000000000000000002.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a714c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df2\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .mode(\"append\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8d72dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_delta=(df3\n",
    "           .write\n",
    "           .format(\"delta\")\n",
    "           .option(\"mergeSchema\", \"true\")\n",
    "           .mode(\"overwrite\") # append\n",
    "           .save(\"output/delta\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls output/delta\n",
    "! echo \"-------------------------------------------------------------------\"\n",
    "! ls output/delta/_delta_log\n",
    "#! cat output/delta/_delta_log/00000000000000000005.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cb3480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"output/delta\")\n",
    "\n",
    "fullHistoryDF = deltaTable.history()    # get the full history of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac186df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|version|readVersion|          timestamp|userId|operation| operationParameters|    operationMetrics|userMetadata|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "|      2|          1|2022-12-05 13:30:56|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 2, n...|        null|\n",
      "|      1|          0|2022-12-05 13:29:29|  null|    WRITE|{mode -> Append, ...|{numFiles -> 2, n...|        null|\n",
      "|      0|       null|2022-12-05 13:27:41|  null|    WRITE|{mode -> Overwrit...|{numFiles -> 3, n...|        null|\n",
      "+-------+-----------+-------------------+------+---------+--------------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullHistoryDF.select(\"version\",\"readVersion\",\"timestamp\",\"userId\",\"operation\",\"operationParameters\",\"operationMetrics\",\"userMetadata\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49f89cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+----+\n",
      "| id|account|dt_transaction|balance| new|\n",
      "+---+-------+--------------+-------+----+\n",
      "|  2|   alex|    2019-02-01|   1500|null|\n",
      "|  3|   alex|    2019-03-01|   1700|null|\n",
      "|  4|  maria|    2020-01-01|   5000|null|\n",
      "|  1|   alex|    2019-01-01|   1000|null|\n",
      "+---+-------+--------------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_parquet=spark.read.format(\"delta\").load(\"output/delta/\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc61efc",
   "metadata": {},
   "source": [
    "## Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6617afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "|  3|   alex|    2019-03-01|   1700|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "|  2|  peter|    2021-01-01|    100|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "|  1|   alex|    2019-03-01|   3300|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").option(\"versuinAsOf\", \"0\").load(\"output/delta\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d249d",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2aea3fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  1|   alex|    2019-03-01|   3300|\n",
      "|  2|  peter|    2021-01-01|    100|\n",
      "+---+-------+--------------+-------+\n",
      "\n",
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "|  3|   alex|    2019-03-01|   1700|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deltaTable2 = DeltaTable.forPath(spark, \"output/delta\")\n",
    "\n",
    "df2.show()\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1688108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+-------+\n",
      "| id|account|dt_transaction|balance|\n",
      "+---+-------+--------------+-------+\n",
      "|  2|  peter|    2021-01-01|    100|\n",
      "|  4|  maria|    2020-01-01|   5000|\n",
      "|  1|   alex|    2019-01-01|   1000|\n",
      "|  1|   alex|    2019-03-01|   3300|\n",
      "|  2|   alex|    2019-02-01|   1500|\n",
      "+---+-------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt3=(deltaTable2.alias(\"oldData\")\n",
    "      .merge(df2.alias(\"newData\"),\n",
    "            \"oldData.account = newData.account AND oldData.dt_transaction = newData.dt_transaction\")\n",
    "            .whenMatchedUpdateAll()\n",
    "            .whenNotMatchedInsertAll()\n",
    "      .execute()\n",
    "    )\n",
    "\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e42a0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------+\n",
      "|account|month|sum(balance)|\n",
      "+-------+-----+------------+\n",
      "|   alex|    1|        1000|\n",
      "|   alex|    2|        1500|\n",
      "|   alex|    3|        3300|\n",
      "|  maria|    1|        5000|\n",
      "|  peter|    1|         100|\n",
      "+-------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=(deltaTable2\n",
    "        .toDF()\n",
    "        .withColumn(\"month\",month(col(\"dt_transaction\")))\n",
    "        .groupBy(\"account\",\"month\").agg(sum(\"balance\"))\n",
    "        .sort(\"account\",\"month\")\n",
    "       )\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2db16769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------+\n",
      "|account|month|sum(balance)|\n",
      "+-------+-----+------------+\n",
      "|   alex|    1|        1000|\n",
      "|   alex|    2|        1500|\n",
      "|   alex|    3|        3300|\n",
      "|  maria|    1|        5000|\n",
      "|  peter|    1|         100|\n",
      "+-------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result=(spark.read\n",
    "        .format(\"delta\")\n",
    "        .option(\"versionAsOf\", \"1\")\n",
    "        .load(\"output/delta\")\n",
    "        .withColumn(\"month\",month(col(\"dt_transaction\")))\n",
    "        .groupBy(\"account\",\"month\").agg(sum(\"balance\"))\n",
    "        .sort(\"account\",\"month\")\n",
    "       )\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe344799",
   "metadata": {},
   "source": [
    "* Schema\n",
    "* Schema evolution\n",
    "* Transaction Log\n",
    "* Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11faea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, May  8 2022, 17:57:49) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
